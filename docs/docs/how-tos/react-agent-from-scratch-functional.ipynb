{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["_\ud55c\uad6d\uc5b4\ub85c \uae30\uacc4\ubc88\uc5ed\ub428_\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# ReAct \uc5d0\uc774\uc804\ud2b8\ub97c \ucc98\uc74c\ubd80\ud130 \ub9cc\ub4dc\ub294 \ubc29\ubc95 (\uae30\ub2a5\uc801 API)\n", "\n", "!!! \uc815\ubcf4 \"\uc804\uc81c \uc870\uac74\"\n", "    \uc774 \uac00\uc774\ub4dc\ub294 \ub2e4\uc74c\uc5d0 \ub300\ud55c \uc774\ud574\ub97c \uc804\uc81c\ub85c \ud569\ub2c8\ub2e4:\n", "    \n", "    - [\ucc44\ud305 \ubaa8\ub378](https://python.langchain.com/docs/concepts/chat_models)\n", "    - [\uba54\uc2dc\uc9c0](https://python.langchain.com/docs/concepts/messages)\n", "    - [\ub3c4\uad6c \ud638\ucd9c](https://python.langchain.com/docs/concepts/tool_calling/)\n", "    - [\uc9c4\uc785\uc810](../../concepts/functional_api/#entrypoint) \ubc0f [\uc791\uc5c5](../../concepts/functional_api/#task)\n", "\n", "\uc774 \uac00\uc774\ub4dc\ub294 LangGraph [\uae30\ub2a5\uc801 API](../../concepts/functional_api)\ub97c \uc0ac\uc6a9\ud558\uc5ec ReAct \uc5d0\uc774\uc804\ud2b8\ub97c \uad6c\ud604\ud558\ub294 \ubc29\ubc95\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\n", "\n", "ReAct \uc5d0\uc774\uc804\ud2b8\ub294 \ub2e4\uc74c\uacfc \uac19\uc774 \uc791\ub3d9\ud558\ub294 [\ub3c4\uad6c \ud638\ucd9c \uc5d0\uc774\uc804\ud2b8](../../concepts/agentic_concepts/#tool-calling-agent)\uc785\ub2c8\ub2e4:\n", "\n", "1. \ucffc\ub9ac\uac00 \ucc44\ud305 \ubaa8\ub378\uc5d0 \ubc1c\ud589\ub429\ub2c8\ub2e4;\n", "2. \ubaa8\ub378\uc774 [\ub3c4\uad6c \ud638\ucd9c](../../concepts/agentic_concepts/#tool-calling)\uc744 \uc0dd\uc131\ud558\uc9c0 \uc54a\uc73c\uba74, \ubaa8\ub378\uc758 \uc751\ub2f5\uc744 \ubc18\ud658\ud569\ub2c8\ub2e4.\n", "3. \ubaa8\ub378\uc774 \ub3c4\uad6c \ud638\ucd9c\uc744 \uc0dd\uc131\ud558\uba74, \uc0ac\uc6a9 \uac00\ub2a5\ud55c \ub3c4\uad6c\ub85c \ub3c4\uad6c \ud638\ucd9c\uc744 \uc2e4\ud589\ud558\uace0, \uc774\ub97c \uba54\uc2dc\uc9c0 \ubaa9\ub85d\uc5d0 [\ub3c4\uad6c \uba54\uc2dc\uc9c0](https://python.langchain.com/docs/concepts/messages/)\ub85c \ucd94\uac00\ud55c \ud6c4, \uc774 \uacfc\uc815\uc744 \ubc18\ubcf5\ud569\ub2c8\ub2e4.\n", "\n", "\uc774\uac83\uc740 \uba54\ubaa8\ub9ac, \uc778\uac04 \ucc38\uc5ec \ub8e8\ud504 \uae30\ub2a5 \ubc0f \uae30\ud0c0 \uae30\ub2a5\uc73c\ub85c \ud655\uc7a5\ud560 \uc218 \uc788\ub294 \uac04\ub2e8\ud558\uace0 \ub2e4\uc7ac\ub2e4\ub2a5\ud55c \uc124\uc815\uc785\ub2c8\ub2e4. \uc608\uc81c\ub294 \uc804\uc6a9 [\ubc29\ubc95 \uc548\ub0b4\uc11c](../../how-tos/#prebuilt-react-agent)\ub97c \ucc38\uc870\ud558\uc138\uc694.\n", "\n", "## \uc124\uc815\n", "\n", "\uba3c\uc800, \ud544\uc694\ud55c \ud328\ud0a4\uc9c0\ub97c \uc124\uce58\ud558\uace0 API \ud0a4\ub97c \uc124\uc815\ud569\uc2dc\ub2e4:\n"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["%%capture --no-stderr\n", "%pip install -U langgraph langchain-openai\n"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["import getpass\n", "import os\n", "\n", "\n", "def _set_env(var: str):\n", "    if not os.environ.get(var):\n", "        os.environ[var] = getpass.getpass(f\"{var}: \")\n", "\n", "\n", "_set_env(\"OPENAI_API_KEY\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"admonition tip\">\n", "     <p class=\"admonition-title\">\ub354 \ub098\uc740 \ub514\ubc84\uae45\uc744 \uc704\ud574 <a href=\"https://smith.langchain.com\">LangSmith</a> \uc124\uc815\ud558\uae30</p>\n", "     <p style=\"padding-top: 5px;\">\n", "         LangSmith\uc5d0 \uac00\uc785\ud558\uc5ec \ubb38\uc81c\ub97c \uc2e0\uc18d\ud558\uac8c \ud30c\uc545\ud558\uace0 LangGraph \ud504\ub85c\uc81d\ud2b8\uc758 \uc131\ub2a5\uc744 \uac1c\uc120\ud558\uc138\uc694. LangSmith\ub294 LangGraph\ub85c \uad6c\ucd95\ub41c LLM \uc571\uc744 \ub514\ubc84\uae45\ud558\uace0 \ud14c\uc2a4\ud2b8\ud558\uba70 \ubaa8\ub2c8\ud130\ub9c1\ud558\ub294 \ub370 \uc0ac\uc6a9\ud560 \uc218 \uc788\ub294 \ucd94\uc801 \ub370\uc774\ud130\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4. \uc2dc\uc791\ud558\ub294 \ubc29\ubc95\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 <a href=\"https://docs.smith.langchain.com\">\ubb38\uc11c</a>\ub97c \ucc38\uc870\ud558\uc138\uc694.\n", "     </p>\n", " </div>\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## ReAct \uc5d0\uc774\uc804\ud2b8 \uc0dd\uc131\n", "\n", "\ud544\uc694\ud55c \ud328\ud0a4\uc9c0\ub97c \uc124\uce58\ud558\uace0 \ud658\uacbd \ubcc0\uc218\ub97c \uc124\uc815\ud588\uc73c\ub2c8, \uc774\uc81c \uc5d0\uc774\uc804\ud2b8\ub97c \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n", "\n", "### \ubaa8\ub378 \ubc0f \ub3c4\uad6c \uc815\uc758\n", "\n", "\uba3c\uc800 \uc608\uc81c\uc5d0 \uc0ac\uc6a9\ud560 \ub3c4\uad6c\uc640 \ubaa8\ub378\uc744 \uc815\uc758\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \uc5ec\uae30\uc5d0\uc11c\ub294 \uc704\uce58\uc758 \ub0a0\uc528\uc5d0 \ub300\ud55c \uc124\uba85\uc744 \uac00\uc838\uc624\ub294 \ub2e8\uc77c \ud50c\ub808\uc774\uc2a4\ud640\ub354 \ub3c4\uad6c\ub97c \uc0ac\uc6a9\ud560 \uac83\uc785\ub2c8\ub2e4.\n", "\n", "\uc774\ubc88 \uc608\uc81c\uc5d0\uc11c\ub294 [OpenAI](https://python.langchain.com/docs/integrations/providers/openai/) \ucc44\ud305 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud560 \uac83\uc774\uc9c0\ub9cc, \ub3c4\uad6c \ud638\ucd9c\uc744 [\uc9c0\uc6d0\ud558\ub294](https://python.langchain.com/docs/integrations/chat/) \ubaa8\ub4e0 \ubaa8\ub378\ub3c4 \uad1c\ucc2e\uc2b5\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["from langchain_openai import ChatOpenAI\n", "from langchain_core.tools import tool\n", "\n", "model = ChatOpenAI(model=\"gpt-4o-mini\")\n", "\n", "\n", "@tool\n", "def get_weather(location: str):\n", "    \"\"\"Call to get the weather from a specific location.\"\"\"\n", "    # This is a placeholder for the actual implementation\n", "    if any([city in location.lower() for city in [\"sf\", \"san francisco\"]]):\n", "        return \"It's sunny!\"\n", "    elif \"boston\" in location.lower():\n", "        return \"It's rainy!\"\n", "    else:\n", "        return f\"I am not sure what the weather is in {location}\"\n", "\n", "\n", "tools = [get_weather]\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### \uc791\uc5c5 \uc815\uc758\n", "\n", "\ub2e4\uc74c\uc73c\ub85c \uc6b0\ub9ac\uac00 \uc2e4\ud589\ud560 [\uc791\uc5c5](../../concepts/functional_api/#task)\uc744 \uc815\uc758\ud569\ub2c8\ub2e4. \uc5ec\uae30\uc5d0\ub294 \ub450 \uac00\uc9c0 \ub2e4\ub978 \uc791\uc5c5\uc774 \uc788\uc2b5\ub2c8\ub2e4:\n", "\n", "1. **\ubaa8\ub378 \ud638\ucd9c**: \uc6b0\ub9ac\ub294 \uba54\uc2dc\uc9c0 \ubaa9\ub85d\uc744 \uc0ac\uc6a9\ud558\uc5ec \ucc44\ud305 \ubaa8\ub378\uc5d0 \ucffc\ub9ac\ub97c \ud558\uace0\uc790 \ud569\ub2c8\ub2e4.\n", "2. **\ub3c4\uad6c \ud638\ucd9c**: \ubaa8\ub378\uc774 \ub3c4\uad6c \ud638\ucd9c\uc744 \uc0dd\uc131\ud558\ub294 \uacbd\uc6b0, \uc6b0\ub9ac\ub294 \uadf8\uac83\uc744 \uc2e4\ud589\ud558\uace0\uc790 \ud569\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["from langchain_core.messages import ToolMessage\n", "from langgraph.func import entrypoint, task\n", "\n", "tools_by_name = {tool.name: tool for tool in tools}\n", "\n", "\n", "@task\n", "def call_model(messages):\n", "    \"\"\"Call model with a sequence of messages.\"\"\"\n", "    response = model.bind_tools(tools).invoke(messages)\n", "    return response\n", "\n", "\n", "@task\n", "def call_tool(tool_call):\n", "    tool = tools_by_name[tool_call[\"name\"]]\n", "    observation = tool.invoke(tool_call[\"args\"])\n", "    return ToolMessage(content=observation, tool_call_id=tool_call[\"id\"])\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### \uc9c4\uc785\uc810 \uc815\uc758\n", "\n", "\uc6b0\ub9ac\uc758 [\uc9c4\uc785\uc810](../../concepts/functional_api/#entrypoint)\uc740 \uc774 \ub450 \uc791\uc5c5\uc758 \uc870\uc815\uc744 \ucc98\ub9ac\ud560 \uac83\uc785\ub2c8\ub2e4. \uc704\uc5d0\uc11c \uc124\uba85\ud55c \ubc14\uc640 \uac19\uc774, `call_model` \uc791\uc5c5\uc774 \ub3c4\uad6c \ud638\ucd9c\uc744 \uc0dd\uc131\ud560 \ub54c, `call_tool` \uc791\uc5c5\uc740 \uac01 \ub3c4\uad6c\uc5d0 \ub300\ud55c \uc751\ub2f5\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc6b0\ub9ac\ub294 \ubaa8\ub4e0 \uba54\uc2dc\uc9c0\ub97c \ub2e8\uc77c \uba54\uc2dc\uc9c0 \ub9ac\uc2a4\ud2b8\uc5d0 \ucd94\uac00\ud569\ub2c8\ub2e4.\n", "\n", "!!! \ud301\n", "    \uc791\uc5c5\uc774 \ubbf8\ub798\uc640 \uc720\uc0ac\ud55c \uac1d\uccb4\ub97c \ubc18\ud658\ud558\uae30 \ub54c\ubb38\uc5d0, \uc544\ub798 \uad6c\ud604\uc740 \ub3c4\uad6c\ub97c \ubcd1\ub82c\ub85c \uc2e4\ud589\ud569\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["from langgraph.graph.message import add_messages\n", "\n", "\n", "@entrypoint()\n", "def agent(messages):\n", "    llm_response = call_model(messages).result()\n", "    while True:\n", "        if not llm_response.tool_calls:\n", "            break\n", "\n", "        # Execute tools\n", "        tool_result_futures = [\n", "            call_tool(tool_call) for tool_call in llm_response.tool_calls\n", "        ]\n", "        tool_results = [fut.result() for fut in tool_result_futures]\n", "\n", "        # Append to message list\n", "        messages = add_messages(messages, [llm_response, *tool_results])\n", "\n", "        # Call model again\n", "        llm_response = call_model(messages).result()\n", "\n", "    return llm_response\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \uc0ac\uc6a9\ubc95\n", "\n", "\uc6b0\ub9ac \uc5d0\uc774\uc804\ud2b8\ub97c \uc0ac\uc6a9\ud558\ub824\uba74 \uba54\uc2dc\uc9c0 \ubaa9\ub85d\uc73c\ub85c \ud638\ucd9c\ud569\ub2c8\ub2e4. \uc6b0\ub9ac\uc758 \uad6c\ud604\uc5d0 \ub530\ub77c, \uc774\uac83\ub4e4\uc740 LangChain [\uba54\uc2dc\uc9c0](https://python.langchain.com/docs/concepts/messages/) \uac1d\uccb4\uc774\uac70\ub098 OpenAI \uc2a4\ud0c0\uc77c\uc758 \ub515\uc154\ub108\ub9ac\uc77c \uc218 \uc788\uc2b5\ub2c8\ub2e4:\n"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'role': 'user', 'content': \"What's the weather in san francisco?\"}\n", "\n", "call_model:\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "Tool Calls:\n", "  get_weather (call_tNnkrjnoz6MNfCHJpwfuEQ0v)\n", " Call ID: call_tNnkrjnoz6MNfCHJpwfuEQ0v\n", "  Args:\n", "    location: san francisco\n", "\n", "call_tool:\n", "=================================\u001b[1m Tool Message \u001b[0m=================================\n", "\n", "It's sunny!\n", "\n", "call_model:\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "\n", "The weather in San Francisco is sunny!\n"]}], "source": ["user_message = {\"role\": \"user\", \"content\": \"What's the weather in san francisco?\"}\n", "print(user_message)\n", "\n", "for step in agent.stream([user_message]):\n", "    for task_name, message in step.items():\n", "        if task_name == \"agent\":\n", "            continue  # Just print task updates\n", "        print(f\"\\n{task_name}:\")\n", "        message.pretty_print()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\uc644\ubcbd\ud569\ub2c8\ub2e4! \uadf8\ub798\ud504\uac00 `get_weather` \ub3c4\uad6c\ub97c \uc62c\ubc14\ub974\uac8c \ud638\ucd9c\ud558\uace0 \ub3c4\uad6c\ub85c\ubd80\ud130 \uc815\ubcf4\ub97c \ubc1b\uc740 \ud6c4 \uc0ac\uc6a9\uc790\uc5d0\uac8c \uc751\ub2f5\ud569\ub2c8\ub2e4. LangSmith \ucd94\uc801\uc744 [\uc5ec\uae30\uc11c](https://smith.langchain.com/public/d5a0d5ea-bdaa-4032-911e-7db177c8141b/r) \ud655\uc778\ud574 \ubcf4\uc138\uc694.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \uc2a4\ub808\ub4dc \uc218\uc900 \uc9c0\uc18d\uc131 \ucd94\uac00\n", "\n", "\uc2a4\ub808\ub4dc \uc218\uc900 \uc9c0\uc18d\uc131\uc744 \ucd94\uac00\ud558\uba74 \uc5d0\uc774\uc804\ud2b8\uc640\uc758 \ub300\ud654 \uacbd\ud5d8\uc744 \uc9c0\uc6d0\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ud6c4\uc758 \ud638\ucd9c\uc740 \uc774\uc804 \uba54\uc2dc\uc9c0 \ubaa9\ub85d\uc5d0 \ucd94\uac00\ub418\uc5b4 \uc804\uccb4 \ub300\ud654 \ub9e5\ub77d\uc744 \uc720\uc9c0\ud569\ub2c8\ub2e4.\n", "\n", "\uc5d0\uc774\uc804\ud2b8\uc5d0 \uc2a4\ub808\ub4dc \uc218\uc900 \uc9c0\uc18d\uc131\uc744 \ucd94\uac00\ud558\ub824\uba74:\n", "\n", "1. \uccb4\ud06c\ud3ec\uc778\ud130\ub97c \uc120\ud0dd\ud569\ub2c8\ub2e4: \uc5ec\uae30\uc11c\ub294 \uac04\ub2e8\ud55c \uc778\uba54\ubaa8\ub9ac \uccb4\ud06c\ud3ec\uc778\ud130\uc778 [MemorySaver](../../reference/checkpoints/#langgraph.checkpoint.memory.MemorySaver)\ub97c \uc0ac\uc6a9\ud560 \uac83\uc785\ub2c8\ub2e4.\n", "2. \uc774\uc804 \uba54\uc2dc\uc9c0 \uc0c1\ud0dc\ub97c \ub450 \ubc88\uc9f8 \uc778\uc218\ub85c \ubc1b\uc744 \uc218 \uc788\ub3c4\ub85d \uc9c4\uc785\uc810\uc744 \uc5c5\ub370\uc774\ud2b8\ud569\ub2c8\ub2e4. \uc5ec\uae30\uc11c\ub294 \uba54\uc2dc\uc9c0 \uc5c5\ub370\uc774\ud2b8\ub97c \uc774\uc804 \uba54\uc2dc\uc9c0 \uc2dc\ud000\uc2a4\uc5d0 \ub2e8\uc21c\ud788 \ucd94\uac00\ud569\ub2c8\ub2e4.\n", "3. \uc6cc\ud06c\ud50c\ub85c\uc6b0\uc5d0\uc11c \uc5b4\ub5a4 \uac12\uc744 \ubc18\ud658\ud560\uc9c0\uc640 \uccb4\ud06c\ud3ec\uc778\ud130\uc5d0 \uc758\ud574 `previous`\ub85c \uc800\uc7a5\ub420 \uac12\uc744 \uc120\ud0dd\ud569\ub2c8\ub2e4. (\uc120\ud0dd \uc0ac\ud56d)\n"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["from langgraph.checkpoint.memory import MemorySaver\n", "\n", "# highlight-next-line\n", "checkpointer = MemorySaver()\n", "\n", "\n", "# highlight-next-line\n", "@entrypoint(checkpointer=checkpointer)\n", "# highlight-next-line\n", "def agent(messages, previous):\n", "    # highlight-next-line\n", "    if previous is not None:\n", "        # highlight-next-line\n", "        messages = add_messages(previous, messages)\n", "\n", "    llm_response = call_model(messages).result()\n", "    while True:\n", "        if not llm_response.tool_calls:\n", "            break\n", "\n", "        # Execute tools\n", "        tool_result_futures = [\n", "            call_tool(tool_call) for tool_call in llm_response.tool_calls\n", "        ]\n", "        tool_results = [fut.result() for fut in tool_result_futures]\n", "\n", "        # Append to message list\n", "        messages = add_messages(messages, [llm_response, *tool_results])\n", "\n", "        # Call model again\n", "        llm_response = call_model(messages).result()\n", "\n", "    # Generate final response\n", "    messages = add_messages(messages, llm_response)\n", "    # highlight-next-line\n", "    return entrypoint.final(value=llm_response, save=messages)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\uc774\uc81c \uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc744 \uc2e4\ud589\ud560 \ub54c \uad6c\uc131(config)\uc744 \uc804\ub2ec\ud574\uc57c \ud569\ub2c8\ub2e4. \uc774 \uad6c\uc131\uc740 \ub300\ud654 \uc2a4\ub808\ub4dc\ub97c \uc2dd\ubcc4\ud558\ub294 \uc2dd\ubcc4\uc790\ub97c \uc9c0\uc815\ud569\ub2c8\ub2e4.\n", "\n", "!!! \ud301\n", "\n", "    \uc2a4\ub808\ub4dc \uc218\uc900 \uc9c0\uc18d\uc131\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 \uc6b0\ub9ac\uc758 [\uac1c\ub150 \ud398\uc774\uc9c0](../../concepts/persistence/)\uc640 [\uc0ac\uc6a9 \ubc29\ubc95 \uac00\uc774\ub4dc](../../how-tos/#persistence)\ub97c \ucc38\uc870\ud558\uc138\uc694.\n"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["config = {\"configurable\": {\"thread_id\": \"1\"}}\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\uc6b0\ub9ac\ub294 \uc774\uc804\uacfc \ub3d9\uc77c\ud55c \ubc29\uc2dd\uc73c\ub85c \uc4f0\ub808\ub4dc\ub97c \uc2dc\uc791\ud558\uc9c0\ub9cc, \uc774\ubc88\uc5d0\ub294 \uc124\uc815\uc744 \uc804\ub2ec\ud569\ub2c8\ub2e4:\n"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'role': 'user', 'content': \"What's the weather in san francisco?\"}\n", "\n", "call_model:\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "Tool Calls:\n", "  get_weather (call_lubbUSdDofmOhFunPEZLBz3g)\n", " Call ID: call_lubbUSdDofmOhFunPEZLBz3g\n", "  Args:\n", "    location: San Francisco\n", "\n", "call_tool:\n", "=================================\u001b[1m Tool Message \u001b[0m=================================\n", "\n", "It's sunny!\n", "\n", "call_model:\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "\n", "The weather in San Francisco is sunny!\n"]}], "source": ["user_message = {\"role\": \"user\", \"content\": \"What's the weather in san francisco?\"}\n", "print(user_message)\n", "\n", "# highlight-next-line\n", "for step in agent.stream([user_message], config):\n", "    for task_name, message in step.items():\n", "        if task_name == \"agent\":\n", "            continue  # Just print task updates\n", "        print(f\"\\n{task_name}:\")\n", "        message.pretty_print()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\ud6c4\uc18d \ub300\ud654\ub97c \uc694\uccad\ud560 \ub54c, \ubaa8\ub378\uc740 \uc774\uc804 \ub9e5\ub77d\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc6b0\ub9ac\uac00 \ub0a0\uc528\uc5d0 \ub300\ud574 \ubb3b\uace0 \uc788\ub2e4\ub294 \uac83\uc744 \ucd94\ub860\ud569\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'role': 'user', 'content': 'How does it compare to Boston, MA?'}\n", "\n", "call_model:\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "Tool Calls:\n", "  get_weather (call_8sTKYAhSIHOdjLD5d6gaswuV)\n", " Call ID: call_8sTKYAhSIHOdjLD5d6gaswuV\n", "  Args:\n", "    location: Boston, MA\n", "\n", "call_tool:\n", "=================================\u001b[1m Tool Message \u001b[0m=================================\n", "\n", "It's rainy!\n", "\n", "call_model:\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "\n", "Compared to San Francisco, which is sunny, Boston, MA is experiencing rainy weather.\n"]}], "source": ["user_message = {\"role\": \"user\", \"content\": \"How does it compare to Boston, MA?\"}\n", "print(user_message)\n", "\n", "for step in agent.stream([user_message], config):\n", "    for task_name, message in step.items():\n", "        if task_name == \"agent\":\n", "            continue  # Just print task updates\n", "        print(f\"\\n{task_name}:\")\n", "        message.pretty_print()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["[LangSmith \ucd94\uc801](https://smith.langchain.com/public/20a1116b-bb3b-44c1-8765-7a28663439d9/r)\uc5d0\uc11c \uac01 \ubaa8\ub378 \ud638\ucd9c\uc5d0\uc11c \uc804\uccb4 \ub300\ud654 \ub9e5\ub77d\uc774 \uc720\uc9c0\ub418\ub294 \uac83\uc744 \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.9"}}}