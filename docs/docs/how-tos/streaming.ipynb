{"cells": [{"cell_type": "markdown", "id": "76c4b04f-0c03-4321-9d40-38d12c59d088", "metadata": {}, "source": ["# \uc2a4\ud2b8\ub9ac\ubc0d\ud558\ub294 \ubc29\ubc95\n"]}, {"cell_type": "markdown", "id": "15403cdb-441d-43af-a29f-fc15abe03dcc", "metadata": {}, "source": ["!!! \uc815\ubcf4 \"\uc804\uc81c \uc870\uac74\"\n", "\n", "    \uc774 \uac00\uc774\ub4dc\ub294 \ub2e4\uc74c \uc0ac\ud56d\uc5d0 \ub300\ud55c \uce5c\uc219\uc131\uc744 \uac00\uc815\ud569\ub2c8\ub2e4:\n", "    \n", "    - [\uc2a4\ud2b8\ub9ac\ubc0d](../../concepts/streaming/)\n", "    - [\ucc44\ud305 \ubaa8\ub378](https://python.langchain.com/docs/concepts/chat_models/)\n", "\n", "\uc2a4\ud2b8\ub9ac\ubc0d\uc740 LLM(\ub300\ud615 \uc5b8\uc5b4 \ubaa8\ub378) \uae30\ubc18 \uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc758 \ubc18\uc751\uc131\uc744 \uac1c\uc120\ud558\ub294 \ub370 \ud544\uc218\uc801\uc785\ub2c8\ub2e4. \ucd9c\ub825 \uacb0\uacfc\ub97c \uc810\uc9c4\uc801\uc73c\ub85c \ud45c\uc2dc\ud568\uc73c\ub85c\uc368, \uc644\uc804\ud55c \uc751\ub2f5\uc774 \uc900\ube44\ub418\uae30 \uc774\uc804\uc5d0\ub3c4 \uc2a4\ud2b8\ub9ac\ubc0d\uc740 \uc0ac\uc6a9\uc790 \uacbd\ud5d8(UX)\uc744 \ud06c\uac8c \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4. \ud2b9\ud788 LLM\uc758 \uc9c0\uc5f0 \ubb38\uc81c\ub97c \ub2e4\ub8e8\ub294 \ub370 \uc720\uc6a9\ud569\ub2c8\ub2e4.\n", "\n", "LangGraph\ub294 \uc2a4\ud2b8\ub9ac\ubc0d\uc744 \uc77c\uae09 \uc9c0\uc6d0\ud569\ub2c8\ub2e4. \uadf8\ub798\ud504 \uc2e4\ud589\uc5d0\uc11c \ucd9c\ub825\uc744 \uc2a4\ud2b8\ub9ac\ubc0d\ud558\ub294 \uc5ec\ub7ec \uac00\uc9c0 \ubc29\ubc95\uc774 \uc788\uc2b5\ub2c8\ub2e4:\n", "\n", "- `\"values\"`: \uac01 \ub2e8\uacc4 \ud6c4 \uc0c1\ud0dc\uc758 \ubaa8\ub4e0 \uac12\uc744 \ubc29\ucd9c\ud569\ub2c8\ub2e4.\n", "- `\"updates\"`: \uac01 \ub2e8\uacc4 \ud6c4 \ub178\ub4dc\uac00 \ubc18\ud658\ud558\ub294 \ub178\ub4dc \uc774\ub984\uacfc \uc5c5\ub370\uc774\ud2b8\ub9cc \ubc29\ucd9c\ud569\ub2c8\ub2e4.\n", "    \uac19\uc740 \ub2e8\uacc4\uc5d0\uc11c \uc5ec\ub7ec \uc5c5\ub370\uc774\ud2b8\uac00 \uc774\ub8e8\uc5b4\uc9c4 \uacbd\uc6b0(\uc608: \uc5ec\ub7ec \ub178\ub4dc \uc2e4\ud589) \ud574\ub2f9 \uc5c5\ub370\uc774\ud2b8\ub294 \ubcc4\ub3c4\ub85c \ubc29\ucd9c\ub429\ub2c8\ub2e4.\n", "- `\"custom\"`: `StreamWriter`\ub97c \uc0ac\uc6a9\ud558\uc5ec \ub178\ub4dc \ub0b4\ubd80\uc5d0\uc11c \uc0ac\uc6a9\uc790 \uc815\uc758 \ub370\uc774\ud130\ub97c \ubc29\ucd9c\ud569\ub2c8\ub2e4.\n", "- [`\"messages\"`](../streaming-tokens): \ub178\ub4dc \ub0b4\ubd80\uc758 LLM \ud638\ucd9c\uc5d0 \ub300\ud55c \uba54\ud0c0\ub370\uc774\ud130\uc640 \ud568\uaed8 LLM \uba54\uc2dc\uc9c0\ub97c \ud1a0\ud070 \ub2e8\uc704\ub85c \ubc29\ucd9c\ud569\ub2c8\ub2e4.\n", "- `\"debug\"`: \uac01 \ub2e8\uacc4\uc5d0 \ub300\ud574 \uac00\ub2a5\ud55c \ub9ce\uc740 \uc815\ubcf4\ub97c \ud3ec\ud568\ud55c \ub514\ubc84\uadf8 \uc774\ubca4\ud2b8\ub97c \ubc29\ucd9c\ud569\ub2c8\ub2e4.\n", "\n", "`graph.stream(..., stream_mode=<stream_mode>)` \uba54\uc11c\ub4dc\ub97c \uc0ac\uc6a9\ud558\uc5ec \uadf8\ub798\ud504\uc5d0\uc11c \ucd9c\ub825\uc744 \uc2a4\ud2b8\ub9ac\ubc0d\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uc5b4:\n", "\n", "=== \"\ub3d9\uae30\"\n", "\n", "    ```python\n", "    for chunk in graph.stream(inputs, stream_mode=\"updates\"):\n", "        print(chunk)\n", "    ```\n", "\n", "=== \"\ube44\ub3d9\uae30\"\n", "\n", "    ```python\n", "    async for chunk in graph.astream(inputs, stream_mode=\"updates\"):\n", "        print(chunk)\n", "    ```\n", "\n", "\uc5ec\ub7ec \uc2a4\ud2b8\ub9ac\ubc0d \ubaa8\ub4dc\ub97c \uacb0\ud569\ud558\uc5ec `stream_mode` \ub9e4\uac1c\ubcc0\uc218\uc5d0 \ub9ac\uc2a4\ud2b8\ub97c \uc81c\uacf5\ud560 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4:\n", "\n", "=== \"\ub3d9\uae30\"\n", "\n", "    ```python\n", "    for chunk in graph.stream(inputs, stream_mode=[\"updates\", \"custom\"]):\n", "        print(chunk)\n", "    ```\n", "\n", "=== \"\ube44\ub3d9\uae30\"\n", "\n", "    ```python\n", "    async for chunk in graph.astream(inputs, stream_mode=[\"updates\", \"custom\"]):\n", "        print(chunk)\n", "    ```\n"]}, {"cell_type": "markdown", "id": "9723cf76-6fe4-4b52-829f-3f28712ddcb7", "metadata": {}, "source": ["## \uc124\uc815\n"]}, {"cell_type": "code", "execution_count": 1, "id": "427f8f66-7404-4c7d-a642-af5053b8b28f", "metadata": {}, "outputs": [], "source": ["%%capture --no-stderr\n", "%pip install --quiet -U langgraph langchain_openai\n"]}, {"cell_type": "code", "execution_count": 2, "id": "03310ce6-e21f-4378-93bf-dd273fdb3e9a", "metadata": {}, "outputs": [{"name": "stdin", "output_type": "stream", "text": ["OPENAI_API_KEY:  \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"]}], "source": ["import getpass\n", "import os\n", "\n", "\n", "def _set_env(var: str):\n", "    if not os.environ.get(var):\n", "        os.environ[var] = getpass.getpass(f\"{var}: \")\n", "\n", "\n", "_set_env(\"OPENAI_API_KEY\")\n"]}, {"cell_type": "markdown", "id": "80399508-bad8-43b7-8ec9-4c06ad1774cc", "metadata": {}, "source": ["<div class=\"admonition tip\">\n", "    <p class=\"admonition-title\">LangGraph \uac1c\ubc1c\uc744 \uc704\ud55c <a href=\"https://smith.langchain.com\">LangSmith</a> \uc124\uc815\ud558\uae30</p>\n", "    <p style=\"padding-top: 5px;\">\n", "        LangSmith\uc5d0 \uac00\uc785\ud558\uc5ec LangGraph \ud504\ub85c\uc81d\ud2b8\uc758 \ubb38\uc81c\ub97c \ube60\ub974\uac8c \ubc1c\uacac\ud558\uace0 \uc131\ub2a5\uc744 \uac1c\uc120\ud558\uc138\uc694. LangSmith\ub97c \uc0ac\uc6a9\ud558\uba74 LangGraph\ub85c \uad6c\ucd95\ub41c LLM \uc571\uc744 \ub514\ubc84\uadf8, \ud14c\uc2a4\ud2b8 \ubc0f \ubaa8\ub2c8\ud130\ub9c1\ud558\uae30 \uc704\ud574 \ucd94\uc801 \ub370\uc774\ud130\ub97c \ud65c\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4 \u2014 \uc2dc\uc791\ud558\ub294 \ubc29\ubc95\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 <a href=\"https://docs.smith.langchain.com\">\uc5ec\uae30</a>\ub97c \uc77d\uc5b4\ubcf4\uc138\uc694.\n", "    </p>\n", "</div>\n"]}, {"cell_type": "markdown", "id": "be4adbb2-61e8-4bb7-942d-b4dc27ba71ac", "metadata": {}, "source": ["\ub450 \uac1c\uc758 \ub178\ub4dc\ub85c \uc774\ub8e8\uc5b4\uc9c4 \uac04\ub2e8\ud55c \uadf8\ub798\ud504\ub97c \uc815\uc758\ud569\uc2dc\ub2e4:\n"]}, {"cell_type": "markdown", "id": "f6d4c513-1006-4179-bba9-d858fc952169", "metadata": {}, "source": ["## \uadf8\ub798\ud504 \uc815\uc758\n"]}, {"cell_type": "code", "execution_count": 3, "id": "faeb5ce8-d383-4277-b0a8-322e713638e4", "metadata": {}, "outputs": [], "source": ["from typing import TypedDict\n", "from langgraph.graph import StateGraph, START\n", "\n", "\n", "class State(TypedDict):\n", "    topic: str\n", "    joke: str\n", "\n", "\n", "def refine_topic(state: State):\n", "    return {\"topic\": state[\"topic\"] + \" and cats\"}\n", "\n", "\n", "def generate_joke(state: State):\n", "    return {\"joke\": f\"This is a joke about {state['topic']}\"}\n", "\n", "\n", "graph = (\n", "    StateGraph(State)\n", "    .add_node(refine_topic)\n", "    .add_node(generate_joke)\n", "    .add_edge(START, \"refine_topic\")\n", "    .add_edge(\"refine_topic\", \"generate_joke\")\n", "    .compile()\n", ")\n"]}, {"cell_type": "markdown", "id": "f9b90850-85bf-4391-b6b7-22ad45edaa3b", "metadata": {}, "source": ["## \uc0c1\ud0dc\uc758 \ubaa8\ub4e0 \uac12 \uc2a4\ud2b8\ub9ac\ubc0d (stream_mode=\"values\") {#values}\n"]}, {"cell_type": "markdown", "id": "d1ed60d4-cf78-4d4d-a660-6879539e168f", "metadata": {}, "source": ["\uc774\uac83\uc744 \uc0ac\uc6a9\ud558\uc5ec \uac01 \ub2e8\uacc4 \ud6c4 **\ubaa8\ub4e0 \uac12**\uc744 \uc0c1\ud0dc\uc5d0\uc11c \uc2a4\ud2b8\ub9ac\ubc0d\ud569\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 4, "id": "3daca06a-369b-41e5-8e4e-6edc4d4af3a7", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'topic': 'ice cream'}\n", "{'topic': 'ice cream and cats'}\n", "{'topic': 'ice cream and cats', 'joke': 'This is a joke about ice cream and cats'}\n"]}], "source": ["for chunk in graph.stream(\n", "    {\"topic\": \"ice cream\"},\n", "    # highlight-next-line\n", "    stream_mode=\"values\",\n", "):\n", "    print(chunk)\n"]}, {"cell_type": "markdown", "id": "adcb1bdb-f9fa-4d42-87ce-8e25d4290883", "metadata": {}, "source": ["## \ub178\ub4dc\uc5d0\uc11c \uc0c1\ud0dc \uc5c5\ub370\uc774\ud2b8 \uc2a4\ud2b8\ub9ac\ubc0d (stream_mode=\"updates\") {#updates}\n"]}, {"cell_type": "markdown", "id": "44c55326-d077-4583-ae5b-396f45daf21c", "metadata": {}, "source": ["\uac01 \ub2e8\uacc4 \ud6c4 \ub178\ub4dc\uc5d0\uc11c \ubc18\ud658\ub41c **\uc0c1\ud0dc \uc5c5\ub370\uc774\ud2b8**\ub9cc \uc2a4\ud2b8\ub9ac\ubc0d\ud558\ub294 \ub370 \uc0ac\uc6a9\ud558\uc138\uc694. \uc2a4\ud2b8\ub9ac\ubc0d\ub41c \ucd9c\ub825\uc5d0\ub294 \ub178\ub4dc\uc758 \uc774\ub984\uacfc \uc5c5\ub370\uc774\ud2b8\uac00 \ud3ec\ud568\ub429\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 5, "id": "eed7d401-37d1-4d15-b6dd-88956fff89e1", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'refine_topic': {'topic': 'ice cream and cats'}}\n", "{'generate_joke': {'joke': 'This is a joke about ice cream and cats'}}\n"]}], "source": ["for chunk in graph.stream(\n", "    {\"topic\": \"ice cream\"},\n", "    # highlight-next-line\n", "    stream_mode=\"updates\",\n", "):\n", "    print(chunk)\n"]}, {"cell_type": "markdown", "id": "b9ed9c68-b7c5-4420-945d-84fa33fcf88f", "metadata": {}, "source": ["## \uc2a4\ud2b8\ub9bc \ub514\ubc84\uadf8 \uc774\ubca4\ud2b8 (stream_mode=\"debug\") {#debug}\n"]}, {"cell_type": "markdown", "id": "94690715-f86c-42f6-be2d-4df82f6f9a96", "metadata": {}, "source": ["\uac01 \ub2e8\uacc4\ubcc4\ub85c \uac00\ub2a5\ud55c \ud55c \ub9ce\uc740 \uc815\ubcf4\ub97c \ud3ec\ud568\ud558\uc5ec **\ub514\ubc84\uadf8 \uc774\ubca4\ud2b8**\ub97c \uc2a4\ud2b8\ub9ac\ubc0d\ud558\ub294 \ub370 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uc5ec\uae30\uc5d0\ub294 \uc2e4\ud589\ub420 \uc608\uc815\uc778 \uc791\uc5c5\uc5d0 \ub300\ud55c \uc815\ubcf4\uc640 \uc791\uc5c5 \uc2e4\ud589 \uacb0\uacfc\uac00 \ud3ec\ud568\ub429\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 6, "id": "cc6354f6-0c39-49cf-a529-b9c6c8713d7c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'type': 'task', 'timestamp': '2025-01-28T22:06:34.789803+00:00', 'step': 1, 'payload': {'id': 'eb305d74-3460-9510-d516-beed71a63414', 'name': 'refine_topic', 'input': {'topic': 'ice cream'}, 'triggers': ['start:refine_topic']}}\n", "{'type': 'task_result', 'timestamp': '2025-01-28T22:06:34.790013+00:00', 'step': 1, 'payload': {'id': 'eb305d74-3460-9510-d516-beed71a63414', 'name': 'refine_topic', 'error': None, 'result': [('topic', 'ice cream and cats')], 'interrupts': []}}\n", "{'type': 'task', 'timestamp': '2025-01-28T22:06:34.790165+00:00', 'step': 2, 'payload': {'id': '74355cb8-6284-25e0-579f-430493c1bdab', 'name': 'generate_joke', 'input': {'topic': 'ice cream and cats'}, 'triggers': ['refine_topic']}}\n", "{'type': 'task_result', 'timestamp': '2025-01-28T22:06:34.790337+00:00', 'step': 2, 'payload': {'id': '74355cb8-6284-25e0-579f-430493c1bdab', 'name': 'generate_joke', 'error': None, 'result': [('joke', 'This is a joke about ice cream and cats')], 'interrupts': []}}\n"]}], "source": ["for chunk in graph.stream(\n", "    {\"topic\": \"ice cream\"},\n", "    # highlight-next-line\n", "    stream_mode=\"debug\",\n", "):\n", "    print(chunk)\n"]}, {"cell_type": "markdown", "id": "6791da60-0513-43e6-b445-788dd81683bb", "metadata": {}, "source": ["## \uc2a4\ud2b8\ub9bc LLM \ud1a0\ud070 ([stream_mode=\"messages\"](../streaming-tokens)) {#messages}\n"]}, {"cell_type": "markdown", "id": "1f45d68b-f7ca-4012-96cc-d276a143f571", "metadata": {}, "source": ["LLM \ud638\ucd9c\uc744 \ud3ec\ud568\ud558\ub3c4\ub85d \uc704\uc758 \uc608\uc81c\ub97c \uc218\uc815\ud569\uc2dc\ub2e4. \uc774\ub97c \ud1b5\ud574 **LLM \uba54\uc2dc\uc9c0\ub97c \ud1a0\ud070 \ub2e8\uc704\ub85c** \uc2a4\ud2b8\ub9ac\ubc0d\ud558\uace0 \ub178\ub4dc\ub098 \uc791\uc5c5 \ub0b4\uc5d0\uc11c LLM \ud638\ucd9c\uc744 \uc704\ud55c \uba54\ud0c0\ub370\uc774\ud130\ub97c \ud568\uaed8 \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 7, "id": "efa787e1-be4d-433b-a1af-46a9c99ad8f3", "metadata": {}, "outputs": [], "source": ["from langchain_openai import ChatOpenAI\n", "\n", "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n", "\n", "\n", "def generate_joke(state: State):\n", "    # highlight-next-line\n", "    llm_response = llm.invoke(\n", "        # highlight-next-line\n", "        [\n", "            # highlight-next-line\n", "            {\"role\": \"user\", \"content\": f\"Generate a joke about {state['topic']}\"}\n", "            # highlight-next-line\n", "        ]\n", "        # highlight-next-line\n", "    )\n", "    return {\"joke\": llm_response.content}\n", "\n", "\n", "graph = (\n", "    StateGraph(State)\n", "    .add_node(refine_topic)\n", "    .add_node(generate_joke)\n", "    .add_edge(START, \"refine_topic\")\n", "    .add_edge(\"refine_topic\", \"generate_joke\")\n", "    .compile()\n", ")\n"]}, {"cell_type": "code", "execution_count": 8, "id": "c251f809-8922-46ea-bd5b-18264fcc523a", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Why| did| the| cat| sit| on| the| ice| cream| cone|?\n", "\n", "|Because| it| wanted| to| be| a| \"|p|urr|-f|ect|\"| scoop|!| \ud83c\udf66|\ud83d\udc31|"]}], "source": ["for message_chunk, metadata in graph.stream(\n", "    {\"topic\": \"ice cream\"},\n", "    # highlight-next-line\n", "    stream_mode=\"messages\",\n", "):\n", "    if message_chunk.content:\n", "        print(message_chunk.content, end=\"|\", flush=True)\n"]}, {"cell_type": "code", "execution_count": 9, "id": "b1912d72-7b68-4810-8b98-d7f3c35fbb6d", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'langgraph_step': 2,\n", " 'langgraph_node': 'generate_joke',\n", " 'langgraph_triggers': ['refine_topic'],\n", " 'langgraph_path': ('__pregel_pull', 'generate_joke'),\n", " 'langgraph_checkpoint_ns': 'generate_joke:568879bc-8800-2b0d-a5b5-059526a4bebf',\n", " 'checkpoint_ns': 'generate_joke:568879bc-8800-2b0d-a5b5-059526a4bebf',\n", " 'ls_provider': 'openai',\n", " 'ls_model_name': 'gpt-4o-mini',\n", " 'ls_model_type': 'chat',\n", " 'ls_temperature': 0.7}"]}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": ["metadata\n"]}, {"cell_type": "markdown", "id": "0d1ebeda-4498-40e0-a30a-0844cb491425", "metadata": {}, "source": ["## \uc0ac\uc6a9\uc790 \uc9c0\uc815 \ub370\uc774\ud130 \uc2a4\ud2b8\ub9ac\ubc0d (stream_mode=\"custom\") {#custom}\n"]}, {"cell_type": "markdown", "id": "e9ca56cc-d36e-4061-b1f6-9ade4e3e00a0", "metadata": {}, "source": ["[`StreamWriter`][langgraph.types.StreamWriter]\ub97c \uc0ac\uc6a9\ud558\uc5ec \ub178\ub4dc \ub0b4\ubd80\uc5d0\uc11c \ucee4\uc2a4\ud140 \ub370\uc774\ud130\ub97c \uc2a4\ud2b8\ub9ac\ubc0d\ud558\uc2ed\uc2dc\uc624.\n"]}, {"cell_type": "code", "execution_count": 10, "id": "e3bf6a2b-afe3-4bd3-8474-57cccd994f23", "metadata": {}, "outputs": [], "source": ["from langgraph.types import StreamWriter\n", "\n", "\n", "# highlight-next-line\n", "def generate_joke(state: State, writer: StreamWriter):\n", "    # highlight-next-line\n", "    writer({\"custom_key\": \"Writing custom data while generating a joke\"})\n", "    return {\"joke\": f\"This is a joke about {state['topic']}\"}\n", "\n", "\n", "graph = (\n", "    StateGraph(State)\n", "    .add_node(refine_topic)\n", "    .add_node(generate_joke)\n", "    .add_edge(START, \"refine_topic\")\n", "    .add_edge(\"refine_topic\", \"generate_joke\")\n", "    .compile()\n", ")\n"]}, {"cell_type": "code", "execution_count": 11, "id": "2ecfb0b0-3311-46f5-9dc8-6c7853373792", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'custom_key': 'Writing custom data while generating a joke'}\n"]}], "source": ["for chunk in graph.stream(\n", "    {\"topic\": \"ice cream\"},\n", "    # highlight-next-line\n", "    stream_mode=\"custom\",\n", "):\n", "    print(chunk)\n"]}, {"cell_type": "markdown", "id": "28e67f4d-fcab-46a8-93e2-b7bee30336c1", "metadata": {}, "source": ["## \uc5ec\ub7ec \uc2a4\ud2b8\ub9ac\ubc0d \ubaa8\ub4dc \uad6c\uc131\ud558\uae30 {#multiple}\n"]}, {"cell_type": "markdown", "id": "01ff946a-f38d-42ad-bc71-a2621fab1b6c", "metadata": {}, "source": ["\uc5ec\ub7ec \uc2a4\ud2b8\ub9ac\ubc0d \ubaa8\ub4dc\ub97c \uacb0\ud569\ud558\ub294 \ub370 \uc0ac\uc6a9\ud558\uc2ed\uc2dc\uc624. \ucd9c\ub825\uc740 \ud29c\ud50c `(\uc2a4\ud2b8\ub9bc_\ubaa8\ub4dc, \uc2a4\ud2b8\ub9ac\ubc0d_\ucd9c\ub825)`\ub85c \uc2a4\ud2b8\ub9ac\ubc0d\ub429\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 12, "id": "bf4cab4b-356c-4276-9035-26974abe1efe", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Stream mode: updates\n", "{'refine_topic': {'topic': 'ice cream and cats'}}\n", "\n", "\n", "Stream mode: custom\n", "{'custom_key': 'Writing custom data while generating a joke'}\n", "\n", "\n", "Stream mode: updates\n", "{'generate_joke': {'joke': 'This is a joke about ice cream and cats'}}\n", "\n", "\n"]}], "source": ["for stream_mode, chunk in graph.stream(\n", "    {\"topic\": \"ice cream\"},\n", "    # highlight-next-line\n", "    stream_mode=[\"updates\", \"custom\"],\n", "):\n", "    print(f\"Stream mode: {stream_mode}\")\n", "    print(chunk)\n", "    print(\"\\n\")\n"]}], "metadata": {"translated_ko": true}}