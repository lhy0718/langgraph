{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["_\ud55c\uad6d\uc5b4\ub85c \uae30\uacc4\ubc88\uc5ed\ub428_\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "d2eecb96-cf0e-47ed-8116-88a7eaa4236d", "metadata": {}, "source": ["# \uadf8\ub798\ud504\uc5d0 \uad50\ucc28 \uc2a4\ub808\ub4dc \uc9c0\uc18d\uc131\uc744 \ucd94\uac00\ud558\ub294 \ubc29\ubc95\n", "\n", "<div class=\"admonition tip\">\n", "    <p class=\"admonition-title\">\uc804\uc81c \uc870\uac74</p>\n", "    <p>\n", "        \uc774 \uac00\uc774\ub4dc\ub294 \ub2e4\uc74c\uc5d0 \ub300\ud55c \uc774\ud574\uac00 \uc788\uc744 \uac83\uc744 \uac00\uc815\ud569\ub2c8\ub2e4:\n", "        <ul>\n", "            <li>\n", "                <a href=\"https://langchain-ai.github.io/langgraph/concepts/persistence/\">\n", "                    \uc9c0\uc18d\uc131\n", "                </a>\n", "            </li>\n", "            <li>\n", "                <a href=\"https://langchain-ai.github.io/langgraph/concepts/memory/\">\n", "                    \uba54\ubaa8\ub9ac\n", "                </a>\n", "            </li>\n", "            <li>\n", "                <a href=\"https://python.langchain.com/docs/concepts/#chat-models/\">\n", "                    \ucc57 \ubaa8\ub378\n", "                </a>\n", "            </li>             \n", "        </ul>\n", "    </p>\n", "</div>\n", "\n", "[\uc774\uc804 \uac00\uc774\ub4dc](https://langchain-ai.github.io/langgraph/how-tos/persistence/)\uc5d0\uc11c\ub294 \ub2e8\uc77c [\uc2a4\ub808\ub4dc]()\uc5d0\uc11c \uc5ec\ub7ec \uc0c1\ud638\uc791\uc6a9 \uac04\uc5d0 \uadf8\ub798\ud504 \uc0c1\ud0dc\ub97c \uc9c0\uc18d\ud558\ub294 \ubc29\ubc95\uc744 \ubc30\uc6e0\uc2b5\ub2c8\ub2e4. LangGraph\ub294 **\uc5ec\ub7ec \uc2a4\ub808\ub4dc** \uac04\uc5d0 \ub370\uc774\ud130\ub97c \uc9c0\uc18d\ud560 \uc218 \uc788\ub3c4\ub85d \ud569\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uc5b4, \uc0ac\uc6a9\uc790\uc758 \uc774\ub984\uc774\ub098 \uc120\ud638\ub3c4\uc640 \uac19\uc740 \uc815\ubcf4\ub97c \uacf5\uc720 \uba54\ubaa8\ub9ac\uc5d0 \uc800\uc7a5\ud558\uace0 \uc0c8\ub85c\uc6b4 \ub300\ud654 \uc2a4\ub808\ub4dc\uc5d0\uc11c \uc7ac\uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n", "\n", "\uc774 \uac00\uc774\ub4dc\uc5d0\uc11c\ub294 [Store](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore) \uc778\ud130\ud398\uc774\uc2a4\ub97c \uc0ac\uc6a9\ud558\uc5ec \uad6c\ud604\ub41c \uacf5\uc720 \uba54\ubaa8\ub9ac\ub97c \uac00\uc9c4 \uadf8\ub798\ud504\ub97c \uad6c\ucd95\ud558\uace0 \uc0ac\uc6a9\ud558\ub294 \ubc29\ubc95\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\n", "\n", "<div class=\"admonition note\">\n", "    <p class=\"admonition-title\">\ucc38\uace0</p>\n", "    <p>\n", "    \uc774 \uac00\uc774\ub4dc\uc5d0\uc11c \uc0ac\uc6a9\ub418\ub294 <code><a href=\"https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore\">Store</a></code> API\uc5d0 \ub300\ud55c \uc9c0\uc6d0\uc740 LangGraph <code>v0.2.32</code>\uc5d0\uc11c \ucd94\uac00\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n", "    </p>\n", "    <p>\n", "    \uc774 \uac00\uc774\ub4dc\uc5d0\uc11c \uc0ac\uc6a9\ub418\ub294 <b>index</b> \ubc0f <b>query</b> \uc778\uc218\uc5d0 \ub300\ud55c \uc9c0\uc6d0\uc740 LangGraph <code>v0.2.54</code>\uc5d0\uc11c \ucd94\uac00\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n", "    </p>\n", "</div>\n", "\n", "## \uc124\uc815\n", "\n", "\uba3c\uc800 \ud544\uc694\ud55c \ud328\ud0a4\uc9c0\ub97c \uc124\uce58\ud558\uace0 API \ud0a4\ub97c \uc124\uc815\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 1, "id": "3457aadf", "metadata": {}, "outputs": [], "source": ["%%capture --no-stderr\n", "%pip install -U langchain_openai langgraph\n"]}, {"cell_type": "code", "execution_count": null, "id": "aa2c64a7", "metadata": {}, "outputs": [], "source": ["import getpass\n", "import os\n", "\n", "\n", "def _set_env(var: str):\n", "    if not os.environ.get(var):\n", "        os.environ[var] = getpass.getpass(f\"{var}: \")\n", "\n", "\n", "_set_env(\"ANTHROPIC_API_KEY\")\n", "_set_env(\"OPENAI_API_KEY\")\n"]}, {"cell_type": "markdown", "id": "51b6817d", "metadata": {}, "source": ["!!! \ud301 \"LangGraph \uac1c\ubc1c\uc744 \uc704\ud574 [LangSmith](https://smith.langchain.com) \uc124\uc815\ud558\uae30\"\n", "\n", "    LangSmith\uc5d0 \uac00\uc785\ud558\uc5ec LangGraph \ud504\ub85c\uc81d\ud2b8\uc758 \ubb38\uc81c\ub97c \uc2e0\uc18d\ud558\uac8c \ubc1c\uacac\ud558\uace0 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0ac \uc218 \uc788\uc2b5\ub2c8\ub2e4. LangSmith\ub97c \uc0ac\uc6a9\ud558\uba74 LangGraph\ub85c \uad6c\ucd95\ub41c LLM \uc571\uc744 \ub514\ubc84\uadf8, \ud14c\uc2a4\ud2b8 \ubc0f \ubaa8\ub2c8\ud130\ub9c1\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub418\ub294 \ucd94\uc801 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4 \u2014 \uc2dc\uc791\ud558\ub294 \ubc29\ubc95\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 [\uc5ec\uae30](https://docs.smith.langchain.com)\ub97c \ucc38\uc870\ud558\uc138\uc694.\n"]}, {"cell_type": "markdown", "id": "c4c550b5-1954-496b-8b9d-800361af17dc", "metadata": {}, "source": ["## \uc800\uc7a5\uc18c \uc815\uc758\n", "\n", "\uc774 \uc608\uc81c\uc5d0\uc11c\ub294 \uc0ac\uc6a9\uc790\uc758 \uc120\ud638\ub3c4\uc5d0 \ub300\ud55c \uc815\ubcf4\ub97c \uac80\uc0c9\ud560 \uc218 \uc788\ub294 \uadf8\ub798\ud504\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc774\ub97c \uc704\ud574 `InMemoryStore`\ub97c \uc815\uc758\ud560 \uac83\uc785\ub2c8\ub2e4. \uc774\ub294 \uba54\ubaa8\ub9ac \ub0b4\uc5d0 \ub370\uc774\ud130\ub97c \uc800\uc7a5\ud558\uace0 \uadf8 \ub370\uc774\ud130\ub97c \ucffc\ub9ac\ud560 \uc218 \uc788\ub294 \uac1d\uccb4\uc785\ub2c8\ub2e4. \uadf8\ub798\ud504\ub97c \ucef4\ud30c\uc77c\ud560 \ub54c \uc800\uc7a5\uc18c \uac1d\uccb4\ub97c \uc804\ub2ec\ud560 \uac83\uc785\ub2c8\ub2e4. \uc774\ub807\uac8c \ud558\uba74 \uadf8\ub798\ud504\uc758 \uac01 \ub178\ub4dc\uac00 \uc800\uc7a5\uc18c\uc5d0 \uc811\uadfc\ud560 \uc218 \uc788\uac8c \ub418\uba70, \ub178\ub4dc \ud568\uc218\ub97c \uc815\uc758\ud560 \ub54c `store` \ud0a4\uc6cc\ub4dc \uc778\uc790\ub97c \uc815\uc758\ud560 \uc218 \uc788\uace0, LangGraph\ub294 \uadf8\ub798\ud504\uc640 \ud568\uaed8 \ucef4\ud30c\uc77c\ud55c \uc800\uc7a5\uc18c \uac1d\uccb4\ub97c \uc790\ub3d9\uc73c\ub85c \uc804\ub2ec\ud569\ub2c8\ub2e4.\n", "\n", "`Store` \uc778\ud130\ud398\uc774\uc2a4\ub97c \uc0ac\uc6a9\ud558\uc5ec \uac1d\uccb4\ub97c \uc800\uc7a5\ud560 \ub54c \ub450 \uac00\uc9c0\ub97c \uc815\uc758\ud569\ub2c8\ub2e4:\n", "\n", "* \uac1d\uccb4\uc758 \ub124\uc784\uc2a4\ud398\uc774\uc2a4, \uc989 \ud29c\ud50c(\ub514\ub809\ud1a0\ub9ac\uc640 \uc720\uc0ac\ud568)\n", "* \uac1d\uccb4 \ud0a4(\ud30c\uc77c\uba85\uacfc \uc720\uc0ac\ud568)\n", "\n", "\uc6b0\ub9ac\uc758 \uc608\uc81c\uc5d0\uc11c\ub294 `(\"memories\", <user_id>)`\ub97c \ub124\uc784\uc2a4\ud398\uc774\uc2a4\ub85c \uc0ac\uc6a9\ud558\uace0 \uac01 \uc0c8\ub85c\uc6b4 \uae30\uc5b5\uc744 \uc704\ud55c \ub79c\ub364 UUID\ub97c \ud0a4\ub85c \uc0ac\uc6a9\ud560 \uac83\uc785\ub2c8\ub2e4.\n", "\n", "\uc911\uc694\ud558\uac8c\ub3c4, \uc0ac\uc6a9\uc790\ub97c \uacb0\uc815\ud558\uae30 \uc704\ud574 `user_id`\ub97c \ub178\ub4dc \ud568\uc218\uc758 config \ud0a4\uc6cc\ub4dc \uc778\uc790\ub97c \ud1b5\ud574 \uc804\ub2ec\ud560 \uac83\uc785\ub2c8\ub2e4.\n", "\n", "\uba3c\uc800, \uc77c\ubd80 \uc0ac\uc6a9\uc790\uc5d0 \ub300\ud55c \uae30\uc5b5\uc73c\ub85c \uc774\ubbf8 \ucc44\uc6cc\uc9c4 `InMemoryStore`\ub97c \uc815\uc758\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 3, "id": "a7f303d6-612e-4e34-bf36-29d4ed25d802", "metadata": {}, "outputs": [], "source": ["from langgraph.store.memory import InMemoryStore\n", "from langchain_openai import OpenAIEmbeddings\n", "\n", "in_memory_store = InMemoryStore(\n", "    index={\n", "        \"embed\": OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n", "        \"dims\": 1536,\n", "    }\n", ")\n"]}, {"cell_type": "markdown", "id": "3389c9f4-226d-40c7-8bfc-ee8aac24f79d", "metadata": {}, "source": ["## \uadf8\ub798\ud504 \uc0dd\uc131\n"]}, {"cell_type": "code", "execution_count": 4, "id": "2a30a362-528c-45ee-9df6-630d2d843588", "metadata": {}, "outputs": [], "source": ["import uuid\n", "from typing import Annotated\n", "from typing_extensions import TypedDict\n", "\n", "from langchain_anthropic import ChatAnthropic\n", "from langchain_core.runnables import RunnableConfig\n", "from langgraph.graph import StateGraph, MessagesState, START\n", "from langgraph.checkpoint.memory import MemorySaver\n", "from langgraph.store.base import BaseStore\n", "\n", "\n", "model = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n", "\n", "\n", "# NOTE: we're passing the Store param to the node --\n", "# this is the Store we compile the graph with\n", "def call_model(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n", "    user_id = config[\"configurable\"][\"user_id\"]\n", "    namespace = (\"memories\", user_id)\n", "    memories = store.search(namespace, query=str(state[\"messages\"][-1].content))\n", "    info = \"\\n\".join([d.value[\"data\"] for d in memories])\n", "    system_msg = f\"You are a helpful assistant talking to the user. User info: {info}\"\n", "\n", "    # Store new memories if the user asks the model to remember\n", "    last_message = state[\"messages\"][-1]\n", "    if \"remember\" in last_message.content.lower():\n", "        memory = \"User name is Bob\"\n", "        store.put(namespace, str(uuid.uuid4()), {\"data\": memory})\n", "\n", "    response = model.invoke(\n", "        [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n", "    )\n", "    return {\"messages\": response}\n", "\n", "\n", "builder = StateGraph(MessagesState)\n", "builder.add_node(\"call_model\", call_model)\n", "builder.add_edge(START, \"call_model\")\n", "\n", "# NOTE: we're passing the store object here when compiling the graph\n", "graph = builder.compile(checkpointer=MemorySaver(), store=in_memory_store)\n", "# If you're using LangGraph Cloud or LangGraph Studio, you don't need to pass the store or checkpointer when compiling the graph, since it's done automatically.\n"]}, {"cell_type": "markdown", "id": "f22a4a18-67e4-4f0b-b655-a29bbe202e1c", "metadata": {}, "source": ["<div class=\"admonition tip\">\n", "    <p class=\"admonition-title\">\ucc38\uace0</p>\n", "    <p>\n", "        LangGraph Cloud\ub098 LangGraph Studio\ub97c \uc0ac\uc6a9\ud558\uace0 \uc788\ub2e4\uba74, \uadf8\ub798\ud504\ub97c \ucef4\ud30c\uc77c\ud560 \ub54c store\ub97c \uc804\ub2ec\ud560 \ud544\uc694\uac00 <strong>\uc5c6\uc2b5\ub2c8\ub2e4</strong>. \uc774\ub294 \uc790\ub3d9\uc73c\ub85c \ucc98\ub9ac\ub418\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4.\n", "    </p>\n", "</div>\n"]}, {"cell_type": "markdown", "id": "552d4e33-556d-4fa5-8094-2a076bc21529", "metadata": {}, "source": ["\uadf8\ub798\ud504\ub97c \uc2e4\ud589\ud558\ub77c!\n"]}, {"cell_type": "markdown", "id": "1842c626-6cd9-4f58-b549-58978e478098", "metadata": {}, "source": ["\uc774\uc81c \uad6c\uc131\uc5d0\uc11c \uc0ac\uc6a9\uc790 ID\ub97c \uc9c0\uc815\ud558\uace0 \ubaa8\ub378\uc5d0\uac8c \uc6b0\ub9ac\uc758 \uc774\ub984\uc744 \uc54c\ub824\uc90d\uc2dc\ub2e4:\n"]}, {"cell_type": "code", "execution_count": 5, "id": "c871a073-a466-46ad-aafe-2b870831057e", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["================================\u001b[1m Human Message \u001b[0m=================================\n", "\n", "Hi! Remember: my name is Bob\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "\n", "Hello Bob! It's nice to meet you. I'll remember that your name is Bob. How can I assist you today?\n"]}], "source": ["config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n", "input_message = {\"role\": \"user\", \"content\": \"Hi! Remember: my name is Bob\"}\n", "for chunk in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n", "    chunk[\"messages\"][-1].pretty_print()\n"]}, {"cell_type": "code", "execution_count": 6, "id": "d862be40-1f8a-4057-81c4-b7bf073dc4c1", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["================================\u001b[1m Human Message \u001b[0m=================================\n", "\n", "what is my name?\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "\n", "Your name is Bob.\n"]}], "source": ["config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n", "input_message = {\"role\": \"user\", \"content\": \"what is my name?\"}\n", "for chunk in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n", "    chunk[\"messages\"][-1].pretty_print()\n"]}, {"cell_type": "markdown", "id": "80fd01ec-f135-4811-8743-daff8daea422", "metadata": {}, "source": ["\uc774\uc81c \uc6b0\ub9ac\uc758 \uc778\uba54\ubaa8\ub9ac \uc2a4\ud1a0\uc5b4\ub97c \uac80\uc0ac\ud558\uace0 \uc2e4\uc81c\ub85c \uc0ac\uc6a9\uc790\uc5d0 \ub300\ud55c \uba54\ubaa8\ub9ac\ub97c \uc800\uc7a5\ud588\ub294\uc9c0 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 7, "id": "76cde493-89cf-4709-a339-207d2b7e9ea7", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'data': 'User name is Bob'}\n"]}], "source": ["for memory in in_memory_store.search((\"memories\", \"1\")):\n", "    print(memory.value)\n"]}, {"cell_type": "markdown", "id": "23f5d7eb-af23-4131-b8fd-2a69e74e6e55", "metadata": {}, "source": ["\uc774\uc81c \uadf8\ub798\ud504\ub97c \ub2e4\ub978 \uc0ac\uc6a9\uc790\uc5d0 \ub300\ud574 \uc2e4\ud589\ud558\uc5ec \uccab \ubc88\uc9f8 \uc0ac\uc6a9\uc790\uc5d0 \ub300\ud55c \uae30\uc5b5\uc774 \ub3c5\ub9bd\uc801\uc778\uc9c0 \ud655\uc778\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 8, "id": "d362350b-d730-48bd-9652-983812fd7811", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["================================\u001b[1m Human Message \u001b[0m=================================\n", "\n", "what is my name?\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "\n", "I apologize, but I don't have any information about your name. As an AI assistant, I don't have access to personal information about users unless it has been specifically shared in our conversation. If you'd like, you can tell me your name and I'll be happy to use it in our discussion.\n"]}], "source": ["config = {\"configurable\": {\"thread_id\": \"3\", \"user_id\": \"2\"}}\n", "input_message = {\"role\": \"user\", \"content\": \"what is my name?\"}\n", "for chunk in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n", "    chunk[\"messages\"][-1].pretty_print()\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.9"}}, "nbformat": 4, "nbformat_minor": 5}