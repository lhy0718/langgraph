{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["_\ud55c\uad6d\uc5b4\ub85c \uae30\uacc4\ubc88\uc5ed\ub428_\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# \uc5d0\uc774\uc804\ud2b8\uc758 \uba54\ubaa8\ub9ac\uc5d0 \uc758\ubbf8\uc801 \uac80\uc0c9 \ucd94\uac00\ud558\ub294 \ubc29\ubc95\n", "\n", "\uc774 \uac00\uc774\ub4dc\ub294 \uc5d0\uc774\uc804\ud2b8\uc758 \uba54\ubaa8\ub9ac \uc800\uc7a5\uc18c\uc5d0\uc11c \uc758\ubbf8\uc801 \uac80\uc0c9\uc744 \ud65c\uc131\ud654\ud558\ub294 \ubc29\ubc95\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \uc800\uc7a5\uc18c\uc5d0\uc11c \uc758\ubbf8\uc801 \uc720\uc0ac\uc131\uc5d0 \ub530\ub77c \ud56d\ubaa9\uc744 \uac80\uc0c9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n", "\n", "!!! \ud301 \uc804\uc81c\uc870\uac74\n", "    \uc774 \uac00\uc774\ub4dc\ub294 [LangGraph\uc758 \uba54\ubaa8\ub9ac](https://langchain-ai.github.io/langgraph/concepts/memory/)\uc5d0 \ub300\ud55c \uae30\ubcf8\uc801\uc778 \uc774\ud574\ub97c \uac00\uc815\ud569\ub2c8\ub2e4.\n", "\n", "\uba3c\uc800, \uc774 \uac00\uc774\ub4dc\uc758 \uc804\uc81c\uc870\uac74\uc744 \uc124\uce58\ud558\uc138\uc694.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%capture --no-stderr\n", "%pip install -U langgraph langchain-openai langchain\n"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["import getpass\n", "import os\n", "\n", "\n", "def _set_env(var: str):\n", "    if not os.environ.get(var):\n", "        os.environ[var] = getpass.getpass(f\"{var}: \")\n", "\n", "\n", "_set_env(\"OPENAI_API_KEY\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\ub2e4\uc74c\uc73c\ub85c, [\uc778\ub371\uc2a4 \uad6c\uc131](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.IndexConfig)\uc73c\ub85c \uc2a4\ud1a0\uc5b4\ub97c \uc0dd\uc131\ud558\uc138\uc694. \uae30\ubcf8\uc801\uc73c\ub85c \uc2a4\ud1a0\uc5b4\ub294 \uc758\ubbf8 \uae30\ubc18/\ubca1\ud130 \uac80\uc0c9 \uc5c6\uc774 \uad6c\uc131\ub429\ub2c8\ub2e4. \uc2a4\ud1a0\uc5b4\ub97c \uc0dd\uc131\ud560 \ub54c [IndexConfig](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.IndexConfig)\ub97c \uc81c\uacf5\ud568\uc73c\ub85c\uc368 \ud56d\ubaa9\uc758 \uc778\ub371\uc2f1\uc744 \uc120\ud0dd\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ub9cc\uc57d \uadc0\ud558\uc758 \uc2a4\ud1a0\uc5b4 \ud074\ub798\uc2a4\uac00 \uc774 \uc778\ud130\ud398\uc774\uc2a4\ub97c \uad6c\ud604\ud558\uc9c0 \uc54a\uac70\ub098 \uc778\ub371\uc2a4 \uad6c\uc131\uc744 \uc804\ub2ec\ud558\uc9c0 \uc54a\uc73c\uba74, \uc758\ubbf8 \uac80\uc0c9\uc740 \ube44\ud65c\uc131\ud654\ub418\uba70 `put` \ub610\ub294 `aput`\uc5d0 \uc804\ub2ec\ub41c \ubaa8\ub4e0 `index` \uc778\uc790\ub294 \ud6a8\uacfc\uac00 \uc5c6\uc2b5\ub2c8\ub2e4. \uc544\ub798\ub294 \uc608\uc2dc\uc785\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["/var/folders/gf/6rnp_mbx5914kx7qmmh7xzmw0000gn/T/ipykernel_83572/2318027494.py:5: LangChainBetaWarning: The function `init_embeddings` is in beta. It is actively being worked on, so the API may change.\n", "  embeddings = init_embeddings(\"openai:text-embedding-3-small\")\n"]}], "source": ["from langchain.embeddings import init_embeddings\n", "from langgraph.store.memory import InMemoryStore\n", "\n", "# Create store with semantic search enabled\n", "embeddings = init_embeddings(\"openai:text-embedding-3-small\")\n", "store = InMemoryStore(\n", "    index={\n", "        \"embed\": embeddings,\n", "        \"dims\": 1536,\n", "    }\n", ")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\uc774\uc81c \uba87 \uac00\uc9c0 \uae30\uc5b5\uc744 \uc800\uc7a5\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4:\n"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# Store some memories\n", "store.put((\"user_123\", \"memories\"), \"1\", {\"text\": \"I love pizza\"})\n", "store.put((\"user_123\", \"memories\"), \"2\", {\"text\": \"I prefer Italian food\"})\n", "store.put((\"user_123\", \"memories\"), \"3\", {\"text\": \"I don't like spicy food\"})\n", "store.put((\"user_123\", \"memories\"), \"3\", {\"text\": \"I am studying econometrics\"})\n", "store.put((\"user_123\", \"memories\"), \"3\", {\"text\": \"I am a plumber\"})\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\uc790\uc5f0\uc5b4\ub97c \uc0ac\uc6a9\ud558\uc5ec \uae30\uc5b5 \uac80\uc0c9\ud558\uae30:\n"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Memory: I prefer Italian food (similarity: 0.46482669521168163)\n", "Memory: I love pizza (similarity: 0.35514845174380766)\n", "Memory: I am a plumber (similarity: 0.155698702336571)\n"]}], "source": ["# Find memories about food preferences\n", "memories = store.search((\"user_123\", \"memories\"), query=\"I like food?\", limit=5)\n", "\n", "for memory in memories:\n", "    print(f'Memory: {memory.value[\"text\"]} (similarity: {memory.score})')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \uc5d0\uc774\uc804\ud2b8\uc5d0\uc11c \uc0ac\uc6a9\ud558\uae30\n", "\n", "\uc2a4\ud1a0\uc5b4\ub97c \uc8fc\uc785\ud558\uc5ec \ubaa8\ub4e0 \ub178\ub4dc\uc5d0 \uc758\ubbf8\ub860\uc801 \uac80\uc0c9\uc744 \ucd94\uac00\ud558\uc2ed\uc2dc\uc624.\n"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["What are you in the mood for? Since you love Italian food and pizza, would you like to order a pizza or try making one at home?"]}], "source": ["from typing import Optional\n", "\n", "from langchain.chat_models import init_chat_model\n", "from langgraph.store.base import BaseStore\n", "\n", "from langgraph.graph import START, MessagesState, StateGraph\n", "\n", "llm = init_chat_model(\"openai:gpt-4o-mini\")\n", "\n", "\n", "def chat(state, *, store: BaseStore):\n", "    # Search based on user's last message\n", "    items = store.search(\n", "        (\"user_123\", \"memories\"), query=state[\"messages\"][-1].content, limit=2\n", "    )\n", "    memories = \"\\n\".join(item.value[\"text\"] for item in items)\n", "    memories = f\"## Memories of user\\n{memories}\" if memories else \"\"\n", "    response = llm.invoke(\n", "        [\n", "            {\"role\": \"system\", \"content\": f\"You are a helpful assistant.\\n{memories}\"},\n", "            *state[\"messages\"],\n", "        ]\n", "    )\n", "    return {\"messages\": [response]}\n", "\n", "\n", "builder = StateGraph(MessagesState)\n", "builder.add_node(chat)\n", "builder.add_edge(START, \"chat\")\n", "graph = builder.compile(store=store)\n", "\n", "for message, metadata in graph.stream(\n", "    input={\"messages\": [{\"role\": \"user\", \"content\": \"I'm hungry\"}]},\n", "    stream_mode=\"messages\",\n", "):\n", "    print(message.content, end=\"\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## `create_react_agent`\uc5d0\uc11c \uc0ac\uc6a9\ud558\uae30\n", "\n", "\ud504\ub86c\ud504\ud2b8 \ud568\uc218\uc5d0 \uc2a4\ud1a0\uc5b4\ub97c \uc8fc\uc785\ud558\uc5ec \ub3c4\uad6c \ud638\ucd9c \uc5d0\uc774\uc804\ud2b8\uc5d0 \uc758\ubbf8 \uae30\ubc18 \uac80\uc0c9\uc744 \ucd94\uac00\ud558\uc138\uc694. \ub610\ud55c \uc5d0\uc774\uc804\ud2b8\uac00 \uae30\uc5b5\uc744 \uc218\ub3d9\uc73c\ub85c \uc800\uc7a5\ud558\uac70\ub098 \uac80\uc0c9\ud560 \uc218 \uc788\ub3c4\ub85d \ub3c4\uad6c\uc5d0\uc11c \uc2a4\ud1a0\uc5b4\ub97c \uc0ac\uc6a9\ud560 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["import uuid\n", "from typing import Optional\n", "\n", "from langchain.chat_models import init_chat_model\n", "from langgraph.prebuilt import InjectedStore\n", "from langgraph.store.base import BaseStore\n", "from typing_extensions import Annotated\n", "\n", "from langgraph.prebuilt import create_react_agent\n", "\n", "\n", "def prepare_messages(state, *, store: BaseStore):\n", "    # Search based on user's last message\n", "    items = store.search(\n", "        (\"user_123\", \"memories\"), query=state[\"messages\"][-1].content, limit=2\n", "    )\n", "    memories = \"\\n\".join(item.value[\"text\"] for item in items)\n", "    memories = f\"## Memories of user\\n{memories}\" if memories else \"\"\n", "    return [\n", "        {\"role\": \"system\", \"content\": f\"You are a helpful assistant.\\n{memories}\"}\n", "    ] + state[\"messages\"]\n", "\n", "\n", "# You can also use the store directly within a tool!\n", "def upsert_memory(\n", "    content: str,\n", "    *,\n", "    memory_id: Optional[uuid.UUID] = None,\n", "    store: Annotated[BaseStore, InjectedStore],\n", "):\n", "    \"\"\"Upsert a memory in the database.\"\"\"\n", "    # The LLM can use this tool to store a new memory\n", "    mem_id = memory_id or uuid.uuid4()\n", "    store.put(\n", "        (\"user_123\", \"memories\"),\n", "        key=str(mem_id),\n", "        value={\"text\": content},\n", "    )\n", "    return f\"Stored memory {mem_id}\"\n", "\n", "\n", "agent = create_react_agent(\n", "    init_chat_model(\"openai:gpt-4o-mini\"),\n", "    tools=[upsert_memory],\n", "    # The 'prompt' function is run to prepare the messages for the LLM. It is called\n", "    # right before each LLM call\n", "    prompt=prepare_messages,\n", "    store=store,\n", ")\n"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["What are you in the mood for? Since you love Italian food and pizza, maybe something in that realm would be great! Would you like suggestions for a specific dish or restaurant?"]}], "source": ["for message, metadata in agent.stream(\n", "    input={\"messages\": [{\"role\": \"user\", \"content\": \"I'm hungry\"}]},\n", "    stream_mode=\"messages\",\n", "):\n", "    print(message.content, end=\"\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \uace0\uae09 \uc0ac\uc6a9\ubc95\n", "\n", "#### \ub2e4\uc911 \ubca1\ud130 \uc778\ub371\uc2f1\n", "\n", "\uae30\uc5b5\uc758 \ub2e4\uc591\ud55c \uce21\uba74\uc744 \ubcc4\ub3c4\ub85c \uc800\uc7a5\ud558\uace0 \uac80\uc0c9\ud558\uc5ec \uc778\ucd9c\uc744 \uac1c\uc120\ud558\uac70\ub098 \ud2b9\uc815 \ud544\ub4dc\ub97c \uc778\ub371\uc2f1\uc5d0\uc11c \uc0dd\ub7b5\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Expect mem 2\n", "Item: mem2; Score (0.5895009051396596)\n", "Memory: Ate alone at home\n", "Emotion: felt a bit lonely\n", "\n", "Expect mem1\n", "Item: mem1; Score (0.6207546534134083)\n", "Memory: Had pizza with friends at Mario's\n", "Emotion: felt happy and connected\n", "\n", "Expect random lower score (ravioli not indexed)\n", "Item: mem1; Score (0.2686278787315685)\n", "Memory: Had pizza with friends at Mario's\n", "Emotion: felt happy and connected\n", "\n"]}], "source": ["# Configure store to embed both memory content and emotional context\n", "store = InMemoryStore(\n", "    index={\"embed\": embeddings, \"dims\": 1536, \"fields\": [\"memory\", \"emotional_context\"]}\n", ")\n", "# Store memories with different content/emotion pairs\n", "store.put(\n", "    (\"user_123\", \"memories\"),\n", "    \"mem1\",\n", "    {\n", "        \"memory\": \"Had pizza with friends at Mario's\",\n", "        \"emotional_context\": \"felt happy and connected\",\n", "        \"this_isnt_indexed\": \"I prefer ravioli though\",\n", "    },\n", ")\n", "store.put(\n", "    (\"user_123\", \"memories\"),\n", "    \"mem2\",\n", "    {\n", "        \"memory\": \"Ate alone at home\",\n", "        \"emotional_context\": \"felt a bit lonely\",\n", "        \"this_isnt_indexed\": \"I like pie\",\n", "    },\n", ")\n", "\n", "# Search focusing on emotional state - matches mem2\n", "results = store.search(\n", "    (\"user_123\", \"memories\"), query=\"times they felt isolated\", limit=1\n", ")\n", "print(\"Expect mem 2\")\n", "for r in results:\n", "    print(f\"Item: {r.key}; Score ({r.score})\")\n", "    print(f\"Memory: {r.value['memory']}\")\n", "    print(f\"Emotion: {r.value['emotional_context']}\\n\")\n", "\n", "# Search focusing on social eating - matches mem1\n", "print(\"Expect mem1\")\n", "results = store.search((\"user_123\", \"memories\"), query=\"fun pizza\", limit=1)\n", "for r in results:\n", "    print(f\"Item: {r.key}; Score ({r.score})\")\n", "    print(f\"Memory: {r.value['memory']}\")\n", "    print(f\"Emotion: {r.value['emotional_context']}\\n\")\n", "\n", "print(\"Expect random lower score (ravioli not indexed)\")\n", "results = store.search((\"user_123\", \"memories\"), query=\"ravioli\", limit=1)\n", "for r in results:\n", "    print(f\"Item: {r.key}; Score ({r.score})\")\n", "    print(f\"Memory: {r.value['memory']}\")\n", "    print(f\"Emotion: {r.value['emotional_context']}\\n\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### \uc800\uc7a5 \uc2dc\uac04\uc5d0 \ud544\ub4dc \uc7ac\uc815\uc758\n", "\ud2b9\uc815 \uba54\ubaa8\ub9ac\ub97c \uc800\uc7a5\ud560 \ub54c `put(..., index=[...fields])`\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc800\uc7a5\uc18c\uc758 \uae30\ubcf8 \uad6c\uc131\uc5d0 \uad00\uacc4\uc5c6\uc774 \uc5b4\ub5a4 \ud544\ub4dc\ub97c \ud3ec\ud568\ud560\uc9c0 \uc7ac\uc815\uc758\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Expect mem1\n", "Item: mem1; Score (0.3374968677940555)\n", "Memory: I love spicy food\n", "Context: At a Thai restaurant\n", "\n", "Expect mem2\n", "Item: mem2; Score (0.36784461593247436)\n", "Memory: The restaurant was too loud\n", "Context: Dinner at an Italian place\n", "\n"]}], "source": ["store = InMemoryStore(\n", "    index={\n", "        \"embed\": embeddings,\n", "        \"dims\": 1536,\n", "        \"fields\": [\"memory\"],\n", "    }  # Default to embed memory field\n", ")\n", "\n", "# Store one memory with default indexing\n", "store.put(\n", "    (\"user_123\", \"memories\"),\n", "    \"mem1\",\n", "    {\"memory\": \"I love spicy food\", \"context\": \"At a Thai restaurant\"},\n", ")\n", "\n", "# Store another overriding which fields to embed\n", "store.put(\n", "    (\"user_123\", \"memories\"),\n", "    \"mem2\",\n", "    {\"memory\": \"The restaurant was too loud\", \"context\": \"Dinner at an Italian place\"},\n", "    index=[\"context\"],  # Override: only embed the context\n", ")\n", "\n", "# Search about food - matches mem1 (using default field)\n", "print(\"Expect mem1\")\n", "results = store.search(\n", "    (\"user_123\", \"memories\"), query=\"what food do they like\", limit=1\n", ")\n", "for r in results:\n", "    print(f\"Item: {r.key}; Score ({r.score})\")\n", "    print(f\"Memory: {r.value['memory']}\")\n", "    print(f\"Context: {r.value['context']}\\n\")\n", "\n", "# Search about restaurant atmosphere - matches mem2 (using overridden field)\n", "print(\"Expect mem2\")\n", "results = store.search(\n", "    (\"user_123\", \"memories\"), query=\"restaurant environment\", limit=1\n", ")\n", "for r in results:\n", "    print(f\"Item: {r.key}; Score ({r.score})\")\n", "    print(f\"Memory: {r.value['memory']}\")\n", "    print(f\"Context: {r.value['context']}\\n\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### \ud2b9\uc815 \uba54\ubaa8\ub9ac\uc5d0 \ub300\ud55c \uc0c9\uc778 \ube44\ud65c\uc131\ud654\n", "\n", "\uc77c\ubd80 \uba54\ubaa8\ub9ac\ub294 \ucf58\ud150\uce20\ub85c \uac80\uc0c9\ud560 \uc218 \uc5c6\uc5b4\uc57c \ud569\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uba54\ubaa8\ub9ac\ub294 \uc5ec\uc804\ud788 \uc800\uc7a5\ud558\uba74\uc11c \uc0c9\uc778\uc744 \ube44\ud65c\uc131\ud654\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc608:\n"]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Expect mem1\n", "Item: mem1; Score (0.32269984224327286)\n", "Memory: I love chocolate ice cream\n", "Type: preference\n", "\n", "Expect low score (mem2 not indexed)\n", "Item: mem1; Score (0.010241633698527089)\n", "Memory: I love chocolate ice cream\n", "Type: preference\n", "\n"]}], "source": ["store = InMemoryStore(index={\"embed\": embeddings, \"dims\": 1536, \"fields\": [\"memory\"]})\n", "\n", "# Store a normal indexed memory\n", "store.put(\n", "    (\"user_123\", \"memories\"),\n", "    \"mem1\",\n", "    {\"memory\": \"I love chocolate ice cream\", \"type\": \"preference\"},\n", ")\n", "\n", "# Store a system memory without indexing\n", "store.put(\n", "    (\"user_123\", \"memories\"),\n", "    \"mem2\",\n", "    {\"memory\": \"User completed onboarding\", \"type\": \"system\"},\n", "    index=False,  # Disable indexing entirely\n", ")\n", "\n", "# Search about food preferences - finds mem1\n", "print(\"Expect mem1\")\n", "results = store.search((\"user_123\", \"memories\"), query=\"what food preferences\", limit=1)\n", "for r in results:\n", "    print(f\"Item: {r.key}; Score ({r.score})\")\n", "    print(f\"Memory: {r.value['memory']}\")\n", "    print(f\"Type: {r.value['type']}\\n\")\n", "\n", "# Search about onboarding - won't find mem2 (not indexed)\n", "print(\"Expect low score (mem2 not indexed)\")\n", "results = store.search((\"user_123\", \"memories\"), query=\"onboarding status\", limit=1)\n", "for r in results:\n", "    print(f\"Item: {r.key}; Score ({r.score})\")\n", "    print(f\"Memory: {r.value['memory']}\")\n", "    print(f\"Type: {r.value['type']}\\n\")\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.9"}}, "nbformat": 4, "nbformat_minor": 5}