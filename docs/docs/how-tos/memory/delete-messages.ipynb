{"cells": [{"cell_type": "markdown", "id": "51466c8d-8ce4-4b3d-be4e-18fdbeda5f53", "metadata": {}, "source": ["# \uba54\uc2dc\uc9c0 \uc0ad\uc81c \ubc29\ubc95\n", "\n", "\uadf8\ub798\ud504\uc758 \uc77c\ubc18\uc801\uc778 \uc0c1\ud0dc \uc911 \ud558\ub098\ub294 \uba54\uc2dc\uc9c0 \ubaa9\ub85d\uc785\ub2c8\ub2e4. \uc77c\ubc18\uc801\uc73c\ub85c \uc774 \uc0c1\ud0dc\uc5d0 \uba54\uc2dc\uc9c0\ub97c \ucd94\uac00\ud558\uae30\ub9cc \ud569\ub2c8\ub2e4. \ud558\uc9c0\ub9cc \ub54c\ub54c\ub85c \uba54\uc2dc\uc9c0\ub97c \uc81c\uac70\ud558\uace0 \uc2f6\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4(\uc0c1\ud0dc\ub97c \uc9c1\uc811 \uc218\uc815\ud558\uac70\ub098 \uadf8\ub798\ud504\uc758 \uc77c\ubd80\ub85c\uc11c). \uc774\ub97c \uc704\ud574 `RemoveMessage` \uc218\uc815\uc790\ub97c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \uac00\uc774\ub4dc\uc5d0\uc11c\ub294 \uadf8 \ubc29\ubc95\uc5d0 \ub300\ud574 \uc124\uba85\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n", "\n", "\ud575\uc2ec \uc544\uc774\ub514\uc5b4\ub294 \uac01 \uc0c1\ud0dc \ud0a4\uc5d0 `reducer` \ud0a4\uac00 \uc788\ub2e4\ub294 \uac83\uc785\ub2c8\ub2e4. \uc774 \ud0a4\ub294 \uc0c1\ud0dc\uc758 \uc5c5\ub370\uc774\ud2b8\ub97c \uacb0\ud569\ud558\ub294 \ubc29\ubc95\uc744 \uc9c0\uc815\ud569\ub2c8\ub2e4. \uae30\ubcf8 `MessagesState`\ub294 \uba54\uc2dc\uc9c0 \ud0a4\uac00 \uc788\uc73c\uba70, \ud574\ub2f9 \ud0a4\uc758 \ub9ac\ub4c0\uc11c\ub294 \uc774\ub7ec\ud55c `RemoveMessage` \uc218\uc815\uc790\ub97c \uc218\uc6a9\ud569\ub2c8\ub2e4. \uadf8 \ub9ac\ub4c0\uc11c\ub294 \uc774\ub7ec\ud55c `RemoveMessage`\ub97c \uc0ac\uc6a9\ud558\uc5ec \ud0a4\uc5d0\uc11c \uba54\uc2dc\uc9c0\ub97c \uc0ad\uc81c\ud569\ub2c8\ub2e4.\n", "\n", "\ub530\ub77c\uc11c \uadf8\ub798\ud504 \uc0c1\ud0dc\uc5d0 \uba54\uc2dc\uc9c0 \ubaa9\ub85d\uc774 \uc788\ub294 \ud0a4\uac00 \uc788\ub2e4\uace0 \ud574\uc11c \uc774 `RemoveMessage` \uc218\uc815\uc790\uac00 \uc791\ub3d9\ud560 \uac83\uc774\ub77c\ub294 \uc758\ubbf8\ub294 \uc544\ub2d9\ub2c8\ub2e4. \uc774\uc640 \ud568\uaed8 \uc791\ub3d9\ud560 \uc218 \uc788\ub294 `reducer`\uac00 \uc815\uc758\ub418\uc5b4 \uc788\uc5b4\uc57c \ud569\ub2c8\ub2e4.\n", "\n", "**\ucc38\uace0**: \ub9ce\uc740 \ubaa8\ub378\uc740 \uba54\uc2dc\uc9c0 \ubaa9\ub85d\uc5d0 \ub300\ud55c \ud2b9\uc815 \uaddc\uce59\uc744 \uae30\ub300\ud569\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uc5b4, \uc77c\ubd80\ub294 \ubaa9\ub85d\uc774 `user` \uba54\uc2dc\uc9c0\ub85c \uc2dc\uc791\ud560 \uac83\uc744 \uae30\ub300\ud558\uace0, \ub2e4\ub978 \uc77c\ubd80\ub294 \ubaa8\ub4e0 \ub3c4\uad6c \ud638\ucd9c \uba54\uc2dc\uc9c0 \ub4a4\uc5d0 \ub3c4\uad6c \uba54\uc2dc\uc9c0\uac00 \uc62c \uac83\uc744 \uae30\ub300\ud569\ub2c8\ub2e4. **\uba54\uc2dc\uc9c0\ub97c \uc0ad\uc81c\ud560 \ub54c \uc774\ub7ec\ud55c \uaddc\uce59\uc744 \uc704\ubc18\ud558\uc9c0 \uc54a\ub3c4\ub85d \uc8fc\uc758\ud574\uc57c \ud569\ub2c8\ub2e4.**\n"]}, {"cell_type": "markdown", "id": "7cbd446a-808f-4394-be92-d45ab818953c", "metadata": {}, "source": ["## \uc124\uc815\n", "\n", "\uba3c\uc800, \uba54\uc2dc\uc9c0\ub97c \uc0ac\uc6a9\ud558\ub294 \uac04\ub2e8\ud55c \uadf8\ub798\ud504\ub97c \ub9cc\ub4e4\uc5b4 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \uc5ec\uae30\uc11c\ub294 \ud544\uc218 `\ub9ac\ub4c0\uc11c`\uac00 \ud3ec\ud568\ub41c `MessagesState`\ub97c \uc0ac\uc6a9\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 1, "id": "af4ce0ba-7596-4e5f-8bf8-0b0bd6e62833", "metadata": {}, "outputs": [], "source": ["%%capture --no-stderr\n", "%pip install --quiet -U langgraph langchain_anthropic\n"]}, {"cell_type": "markdown", "id": "0abe11f4-62ed-4dc4-8875-3db21e260d1d", "metadata": {}, "source": ["\ub2e4\uc74c\uc73c\ub85c, \uc6b0\ub9ac\uac00 \uc0ac\uc6a9\ud560 LLM\uc778 Anthropic\uc758 API \ud0a4\ub97c \uc124\uc815\ud574\uc57c \ud569\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 2, "id": "c903a1cf-2977-4e2d-ad7d-8b3946821d89", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["ANTHROPIC_API_KEY:  \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"]}], "source": ["import getpass\n", "import os\n", "\n", "\n", "def _set_env(var: str):\n", "    if not os.environ.get(var):\n", "        os.environ[var] = getpass.getpass(f\"{var}: \")\n", "\n", "\n", "_set_env(\"ANTHROPIC_API_KEY\")\n"]}, {"cell_type": "markdown", "id": "f0ed46a8-effe-4596-b0e1-a6a29ee16f5c", "metadata": {}, "source": ["<div class=\"admonition tip\">\n", "    <p class=\"admonition-title\">LangGraph \uac1c\ubc1c\uc744 \uc704\ud55c <a href=\"https://smith.langchain.com\">LangSmith</a> \uc124\uc815\ud558\uae30</p>\n", "    <p style=\"padding-top: 5px;\">\n", "        LangSmith\uc5d0 \uac00\uc785\ud558\uc5ec LangGraph \ud504\ub85c\uc81d\ud2b8\uc758 \ubb38\uc81c\ub97c \uc2e0\uc18d\ud558\uac8c \ubc1c\uacac\ud558\uace0 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\uc138\uc694. LangSmith\ub294 \ucd94\uc801 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud558\uc5ec LangGraph\ub85c \uad6c\ucd95\ub41c LLM \uc571\uc744 \ub514\ubc84\uadf8\ud558\uace0 \ud14c\uc2a4\ud2b8\ud558\uba70 \ubaa8\ub2c8\ud130\ub9c1\ud560 \uc218 \uc788\uac8c \ud574\uc90d\ub2c8\ub2e4 \u2014 \uc2dc\uc791\ud558\ub294 \ubc29\ubc95\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 <a href=\"https://docs.smith.langchain.com\">\uc5ec\uae30</a>\ub97c \uc77d\uc5b4\ubcf4\uc138\uc694.\n", "    </p>\n", "</div>\n"]}, {"cell_type": "markdown", "id": "4767ef1c-a7cf-41f8-a301-558988cb7ac5", "metadata": {}, "source": ["## \uc5d0\uc774\uc804\ud2b8 \uad6c\ucd95\ud558\uae30\n", "\uc774\uc81c \uac04\ub2e8\ud55c ReAct \uc2a4\ud0c0\uc77c\uc758 \uc5d0\uc774\uc804\ud2b8\ub97c \uad6c\ucd95\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 7, "id": "378899a9-3b9a-4748-95b6-eb00e0828677", "metadata": {}, "outputs": [], "source": ["from typing import Literal\n", "\n", "from langchain_anthropic import ChatAnthropic\n", "from langchain_core.tools import tool\n", "\n", "from langgraph.checkpoint.memory import MemorySaver\n", "from langgraph.graph import MessagesState, StateGraph, START, END\n", "from langgraph.prebuilt import ToolNode\n", "\n", "memory = MemorySaver()\n", "\n", "\n", "@tool\n", "def search(query: str):\n", "    \"\"\"Call to surf the web.\"\"\"\n", "    # This is a placeholder for the actual implementation\n", "    # Don't let the LLM know this though \ud83d\ude0a\n", "    return \"It's sunny in San Francisco, but you better look out if you're a Gemini \ud83d\ude08.\"\n", "\n", "\n", "tools = [search]\n", "tool_node = ToolNode(tools)\n", "model = ChatAnthropic(model_name=\"claude-3-haiku-20240307\")\n", "bound_model = model.bind_tools(tools)\n", "\n", "\n", "def should_continue(state: MessagesState):\n", "    \"\"\"Return the next node to execute.\"\"\"\n", "    last_message = state[\"messages\"][-1]\n", "    # If there is no function call, then we finish\n", "    if not last_message.tool_calls:\n", "        return END\n", "    # Otherwise if there is, we continue\n", "    return \"action\"\n", "\n", "\n", "# Define the function that calls the model\n", "def call_model(state: MessagesState):\n", "    response = model.invoke(state[\"messages\"])\n", "    # We return a list, because this will get added to the existing list\n", "    return {\"messages\": response}\n", "\n", "\n", "# Define a new graph\n", "workflow = StateGraph(MessagesState)\n", "\n", "# Define the two nodes we will cycle between\n", "workflow.add_node(\"agent\", call_model)\n", "workflow.add_node(\"action\", tool_node)\n", "\n", "# Set the entrypoint as `agent`\n", "# This means that this node is the first one called\n", "workflow.add_edge(START, \"agent\")\n", "\n", "# We now add a conditional edge\n", "workflow.add_conditional_edges(\n", "    # First, we define the start node. We use `agent`.\n", "    # This means these are the edges taken after the `agent` node is called.\n", "    \"agent\",\n", "    # Next, we pass in the function that will determine which node is called next.\n", "    should_continue,\n", "    # Next, we pass in the path map - all the possible nodes this edge could go to\n", "    [\"action\", END],\n", ")\n", "\n", "# We now add a normal edge from `tools` to `agent`.\n", "# This means that after `tools` is called, `agent` node is called next.\n", "workflow.add_edge(\"action\", \"agent\")\n", "\n", "# Finally, we compile it!\n", "# This compiles it into a LangChain Runnable,\n", "# meaning you can use it as you would any other runnable\n", "app = workflow.compile(checkpointer=memory)\n"]}, {"cell_type": "code", "execution_count": 8, "id": "57b27553-21be-43e5-ac48-d1d0a3aa0dca", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["================================\u001b[1m Human Message \u001b[0m=================================\n", "\n", "hi! I'm bob\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "\n", "It's nice to meet you, Bob! I'm an AI assistant created by Anthropic. I'm here to help out with any questions or tasks you might have. Please let me know if there's anything I can assist you with.\n", "================================\u001b[1m Human Message \u001b[0m=================================\n", "\n", "what's my name?\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "\n", "You said your name is Bob.\n"]}], "source": ["from langchain_core.messages import HumanMessage\n", "\n", "config = {\"configurable\": {\"thread_id\": \"2\"}}\n", "input_message = HumanMessage(content=\"hi! I'm bob\")\n", "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n", "    event[\"messages\"][-1].pretty_print()\n", "\n", "\n", "input_message = HumanMessage(content=\"what's my name?\")\n", "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n", "    event[\"messages\"][-1].pretty_print()\n"]}, {"cell_type": "markdown", "id": "2fb0de5b-30ec-42d4-813a-7ad63fe1c367", "metadata": {}, "source": ["## \uc218\ub3d9\uc73c\ub85c \uba54\uc2dc\uc9c0 \uc0ad\uc81c\ud558\uae30\n", "\n", "\uba3c\uc800, \uc218\ub3d9\uc73c\ub85c \uba54\uc2dc\uc9c0\ub97c \uc0ad\uc81c\ud558\ub294 \ubc29\ubc95\uc744 \ub2e4\ub8e8\uaca0\uc2b5\ub2c8\ub2e4. \ud604\uc7ac \uc2a4\ub808\ub4dc\uc758 \uc0c1\ud0dc\ub97c \uc0b4\ud3b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4:\n"]}, {"cell_type": "code", "execution_count": 9, "id": "8a850529-d038-48f7-b5a2-8d4d2923f83a", "metadata": {}, "outputs": [{"data": {"text/plain": ["[HumanMessage(content=\"hi! I'm bob\", additional_kwargs={}, response_metadata={}, id='db576005-3a60-4b3b-8925-dc602ac1c571'),\n", " AIMessage(content=\"It's nice to meet you, Bob! I'm an AI assistant created by Anthropic. I'm here to help out with any questions or tasks you might have. Please let me know if there's anything I can assist you with.\", additional_kwargs={}, response_metadata={'id': 'msg_01BKAnYxmoC6bQ9PpCuHk8ZT', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 12, 'output_tokens': 52}}, id='run-3a60c536-b207-4c56-98f3-03f94d49a9e4-0', usage_metadata={'input_tokens': 12, 'output_tokens': 52, 'total_tokens': 64}),\n", " HumanMessage(content=\"what's my name?\", additional_kwargs={}, response_metadata={}, id='2088c465-400b-430b-ad80-fad47dc1f2d6'),\n", " AIMessage(content='You said your name is Bob.', additional_kwargs={}, response_metadata={'id': 'msg_013UWTLTzwZi81vke8mMQ2KP', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 72, 'output_tokens': 10}}, id='run-3a6883be-0c52-4938-af98-e9e7476659eb-0', usage_metadata={'input_tokens': 72, 'output_tokens': 10, 'total_tokens': 82})]"]}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": ["messages = app.get_state(config).values[\"messages\"]\n", "messages\n"]}, {"cell_type": "markdown", "id": "81be8a0a-1e94-4302-bd84-d1b72e3c501c", "metadata": {}, "source": ["\uc6b0\ub9ac\ub294 `update_state`\ub97c \ud638\ucd9c\ud558\uace0 \uccab \ubc88\uc9f8 \uba54\uc2dc\uc9c0\uc758 ID\ub97c \uc804\ub2ec\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub807\uac8c \ud558\uba74 \ud574\ub2f9 \uba54\uc2dc\uc9c0\uac00 \uc0ad\uc81c\ub429\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 10, "id": "df1a0970-7e64-4170-beef-2855d10eef42", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'configurable': {'thread_id': '2',\n", "  'checkpoint_ns': '',\n", "  'checkpoint_id': '1ef75157-f251-6a2a-8005-82a86a6593a0'}}"]}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": ["from langchain_core.messages import RemoveMessage\n", "\n", "app.update_state(config, {\"messages\": RemoveMessage(id=messages[0].id)})\n"]}, {"cell_type": "markdown", "id": "9c9127ae-0d42-42b8-957f-ea69a5da555f", "metadata": {}, "source": ["\ud604\uc7ac \uba54\uc2dc\uc9c0\ub97c \uc0b4\ud3b4\ubcf4\uba74 \uccab \ubc88\uc9f8 \uba54\uc2dc\uc9c0\uac00 \uc0ad\uc81c\ub418\uc5c8\uc74c\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 8, "id": "8bfe4ffa-e170-43bc-aec4-6e36ac620931", "metadata": {}, "outputs": [{"data": {"text/plain": ["[AIMessage(content=\"It's nice to meet you, Bob! I'm Claude, an AI assistant created by Anthropic. How can I assist you today?\", response_metadata={'id': 'msg_01XPSAenmSqK8rX2WgPZHfz7', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 12, 'output_tokens': 32}}, id='run-1c69af09-adb1-412d-9010-2456e5a555fb-0', usage_metadata={'input_tokens': 12, 'output_tokens': 32, 'total_tokens': 44}),\n", " HumanMessage(content=\"what's my name?\", id='f3c71afe-8ce2-4ed0-991e-65021f03b0a5'),\n", " AIMessage(content='Your name is Bob, as you introduced yourself at the beginning of our conversation.', response_metadata={'id': 'msg_01BPZdwsjuMAbC1YAkqawXaF', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 52, 'output_tokens': 19}}, id='run-b2eb9137-2f4e-446f-95f5-3d5f621a2cf8-0', usage_metadata={'input_tokens': 52, 'output_tokens': 19, 'total_tokens': 71})]"]}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": ["messages = app.get_state(config).values[\"messages\"]\n", "messages\n"]}, {"cell_type": "markdown", "id": "ef129a75-4cad-44d7-b532-eb37b0553c0c", "metadata": {}, "source": ["## \ud504\ub85c\uadf8\ub798\ubc0d \ubc29\uc2dd\uc73c\ub85c \uba54\uc2dc\uc9c0 \uc0ad\uc81c\ud558\uae30\n", "\n", "\uc6b0\ub9ac\ub294 \uadf8\ub798\ud504 \ub0b4\ubd80\uc5d0\uc11c \ud504\ub85c\uadf8\ub798\ubc0d \ubc29\uc2dd\uc73c\ub85c \uba54\uc2dc\uc9c0\ub97c \uc0ad\uc81c\ud560 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4. \uc5ec\uae30\uc11c\ub294 \uadf8\ub798\ud504 \uc2e4\ud589\uc758 \ub05d\uc5d0\uc11c 3\uac1c \uc774\uc0c1\uc758 \uc624\ub798\ub41c \uba54\uc2dc\uc9c0\ub97c \uc0ad\uc81c\ud558\ub3c4\ub85d \uadf8\ub798\ud504\ub97c \uc218\uc815\ud560 \uac83\uc785\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 9, "id": "bb22ede0-e153-4fd0-a4c0-f9af2f7663b1", "metadata": {}, "outputs": [], "source": ["from langchain_core.messages import RemoveMessage\n", "from langgraph.graph import END\n", "\n", "\n", "def delete_messages(state):\n", "    messages = state[\"messages\"]\n", "    if len(messages) > 3:\n", "        return {\"messages\": [RemoveMessage(id=m.id) for m in messages[:-3]]}\n", "\n", "\n", "# We need to modify the logic to call delete_messages rather than end right away\n", "def should_continue(state: MessagesState) -> Literal[\"action\", \"delete_messages\"]:\n", "    \"\"\"Return the next node to execute.\"\"\"\n", "    last_message = state[\"messages\"][-1]\n", "    # If there is no function call, then we call our delete_messages function\n", "    if not last_message.tool_calls:\n", "        return \"delete_messages\"\n", "    # Otherwise if there is, we continue\n", "    return \"action\"\n", "\n", "\n", "# Define a new graph\n", "workflow = StateGraph(MessagesState)\n", "workflow.add_node(\"agent\", call_model)\n", "workflow.add_node(\"action\", tool_node)\n", "\n", "# This is our new node we're defining\n", "workflow.add_node(delete_messages)\n", "\n", "\n", "workflow.add_edge(START, \"agent\")\n", "workflow.add_conditional_edges(\n", "    \"agent\",\n", "    should_continue,\n", ")\n", "workflow.add_edge(\"action\", \"agent\")\n", "\n", "# This is the new edge we're adding: after we delete messages, we finish\n", "workflow.add_edge(\"delete_messages\", END)\n", "app = workflow.compile(checkpointer=memory)\n"]}, {"cell_type": "markdown", "id": "52cbdef6-7db7-45a2-8194-de4f8929bd1f", "metadata": {}, "source": ["\uc774\uc81c \uc774\uac83\uc744 \uc2dc\ub3c4\ud574 \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc6b0\ub9ac\ub294 \uadf8\ub798\ud504\ub97c \ub450 \ubc88 \ud638\ucd9c\ud55c \ub2e4\uc74c \uc0c1\ud0dc\ub97c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 10, "id": "3975f34c-c243-40ea-b9d2-424d50a48dc9", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[('human', \"hi! I'm bob\")]\n", "[('human', \"hi! I'm bob\"), ('ai', \"Hello Bob! It's nice to meet you. I'm an AI assistant created by Anthropic. I'm here to help with any questions or tasks you might have. Please let me know how I can assist you.\")]\n", "[('human', \"hi! I'm bob\"), ('ai', \"Hello Bob! It's nice to meet you. I'm an AI assistant created by Anthropic. I'm here to help with any questions or tasks you might have. Please let me know how I can assist you.\"), ('human', \"what's my name?\")]\n", "[('human', \"hi! I'm bob\"), ('ai', \"Hello Bob! It's nice to meet you. I'm an AI assistant created by Anthropic. I'm here to help with any questions or tasks you might have. Please let me know how I can assist you.\"), ('human', \"what's my name?\"), ('ai', 'You said your name is Bob, so that is the name I have for you.')]\n", "[('ai', \"Hello Bob! It's nice to meet you. I'm an AI assistant created by Anthropic. I'm here to help with any questions or tasks you might have. Please let me know how I can assist you.\"), ('human', \"what's my name?\"), ('ai', 'You said your name is Bob, so that is the name I have for you.')]\n"]}], "source": ["from langchain_core.messages import HumanMessage\n", "\n", "config = {\"configurable\": {\"thread_id\": \"3\"}}\n", "input_message = HumanMessage(content=\"hi! I'm bob\")\n", "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n", "    print([(message.type, message.content) for message in event[\"messages\"]])\n", "\n", "\n", "input_message = HumanMessage(content=\"what's my name?\")\n", "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n", "    print([(message.type, message.content) for message in event[\"messages\"]])\n"]}, {"cell_type": "markdown", "id": "67b2fd2a-14a1-4c47-8632-f8cbb0ba1d35", "metadata": {}, "source": ["\ud604\uc7ac \uc0c1\ud0dc\ub97c \ud655\uc778\ud558\uba74 \uc138 \uac1c\uc758 \uba54\uc2dc\uc9c0\ub9cc \ud45c\uc2dc\ub418\uc5b4\uc57c \ud569\ub2c8\ub2e4. \uc774\ub294 \uc6b0\ub9ac\uac00 \uc774\uc804 \uba54\uc2dc\uc9c0\ub97c \uc0ad\uc81c\ud588\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4. \uadf8\ub807\uc9c0 \uc54a\uc558\ub2e4\uba74 \ub124 \uac1c\uac00 \ub418\uc5c8\uc744 \uac83\uc785\ub2c8\ub2e4!\n"]}, {"cell_type": "code", "execution_count": 11, "id": "a3e15abb-81d8-4072-9f10-61ae0fd61dac", "metadata": {}, "outputs": [{"data": {"text/plain": ["[AIMessage(content=\"Hello Bob! It's nice to meet you. I'm an AI assistant created by Anthropic. I'm here to help with any questions or tasks you might have. Please let me know how I can assist you.\", response_metadata={'id': 'msg_01XPEgPPbcnz5BbGWUDWTmzG', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 12, 'output_tokens': 48}}, id='run-eded3820-b6a9-4d66-9210-03ca41787ce6-0', usage_metadata={'input_tokens': 12, 'output_tokens': 48, 'total_tokens': 60}),\n", " HumanMessage(content=\"what's my name?\", id='a0ea2097-3280-402b-92e1-67177b807ae8'),\n", " AIMessage(content='You said your name is Bob, so that is the name I have for you.', response_metadata={'id': 'msg_01JGT62pxhrhN4SykZ57CSjW', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 68, 'output_tokens': 20}}, id='run-ace3519c-81f8-45fe-a777-91f42d48b3a3-0', usage_metadata={'input_tokens': 68, 'output_tokens': 20, 'total_tokens': 88})]"]}, "execution_count": 11, "metadata": {}, "output_type": "execute_result"}], "source": ["messages = app.get_state(config).values[\"messages\"]\n", "messages\n"]}, {"cell_type": "markdown", "id": "359cfeae-d43a-46ee-9069-a1cab9a5720a", "metadata": {}, "source": ["\uba54\uc2dc\uc9c0\ub97c \uc0ad\uc81c\ud560 \ub54c \ub0a8\uc544 \uc788\ub294 \uba54\uc2dc\uc9c0 \ubaa9\ub85d\uc774 \uc5ec\uc804\ud788 \uc720\ud6a8\ud55c\uc9c0 \ud655\uc778\ud574\uc57c \ud569\ub2c8\ub2e4. \uc774 \uba54\uc2dc\uc9c0 \ubaa9\ub85d\uc740 **\uc2e4\uc81c\ub85c \uc720\ud6a8\ud558\uc9c0 \uc54a\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4** - \uc774\ub294 \ud604\uc7ac AI \uba54\uc2dc\uc9c0\ub85c \uc2dc\uc791\ud558\uace0 \uc788\uae30 \ub54c\ubb38\uc778\ub370, \uc77c\ubd80 \ubaa8\ub378\uc5d0\uc11c\ub294 \uc774\uac83\uc744 \ud5c8\uc6a9\ud558\uc9c0 \uc54a\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4.\n"]}], "metadata": {"translated_ko": true}}