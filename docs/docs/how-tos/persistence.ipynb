{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["_\ud55c\uad6d\uc5b4\ub85c \uae30\uacc4\ubc88\uc5ed\ub428_\n"]}, {"cell_type": "markdown", "id": "51466c8d-8ce4-4b3d-be4e-18fdbeda5f53", "metadata": {}, "source": ["# \uadf8\ub798\ud504\uc5d0 \uc2a4\ub808\ub4dc \uc218\uc900\uc758 \uc9c0\uc18d\uc131\uc744 \ucd94\uac00\ud558\ub294 \ubc29\ubc95\n", "\n", "<div class=\"admonition tip\">\n", "    <p class=\"admonition-title\">\uc804\uc81c \uc870\uac74</p>\n", "    <p>\n", "        \uc774 \uac00\uc774\ub4dc\ub294 \ub2e4\uc74c \ub0b4\uc6a9\uc744 \uc54c\uace0 \uc788\ub2e4\uace0 \uac00\uc815\ud569\ub2c8\ub2e4:\n", "        <ul>\n", "            <li>\n", "                <a href=\"https://langchain-ai.github.io/langgraph/concepts/persistence/\">\n", "                    \uc9c0\uc18d\uc131\n", "                </a>\n", "            </li>\n", "            <li>\n", "                <a href=\"https://langchain-ai.github.io/langgraph/concepts/memory/\">\n", "                    \uba54\ubaa8\ub9ac\n", "                </a>\n", "            </li>\n", "            <li>\n", "                <a href=\"https://python.langchain.com/docs/concepts/#chat-models/\">\n", "                    \ucc57 \ubaa8\ub378\n", "                </a>\n", "            </li>        \n", "        </ul>\n", "    </p>\n", "</div> \n", "\n", "\ub9ce\uc740 AI \uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc740 \uc5ec\ub7ec \uc0c1\ud638\uc791\uc6a9 \uac04\uc5d0 \ub9e5\ub77d\uc744 \uacf5\uc720\ud558\uae30 \uc704\ud574 \uba54\ubaa8\ub9ac\uac00 \ud544\uc694\ud569\ub2c8\ub2e4. LangGraph\uc5d0\uc11c\ub294 \uc774\ub7ec\ud55c \uc720\ud615\uc758 \uba54\ubaa8\ub9ac\ub97c [\uc2a4\ub808\ub4dc \uc218\uc900\uc758 \uc9c0\uc18d\uc131](https://langchain-ai.github.io/langgraph/concepts/persistence)\uc73c\ub85c \ubaa8\ub4e0 [StateGraph](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.StateGraph)\uc5d0 \ucd94\uac00\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n", "\n", "LangGraph \uadf8\ub798\ud504\ub97c \uc0dd\uc131\ud560 \ub54c, \uadf8\ub798\ud504\ub97c \ucef4\ud30c\uc77c\ud560 \ub54c [\uccb4\ud06c\ud3ec\uc778\ud130](https://langchain-ai.github.io/langgraph/reference/checkpoints/#basecheckpointsaver)\ub97c \ucd94\uac00\ud558\uc5ec \uc0c1\ud0dc\ub97c \uc9c0\uc18d\ud558\ub3c4\ub85d \uc124\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4:\n", "\n", "```python\n", "from langgraph.checkpoint.memory import MemorySaver\n", "\n", "checkpointer = MemorySaver()\n", "graph.compile(checkpointer=checkpointer)\n", "```\n", "\n", "\uc774 \uac00\uc774\ub4dc\ub294 \uadf8\ub798\ud504\uc5d0 \uc2a4\ub808\ub4dc \uc218\uc900\uc758 \uc9c0\uc18d\uc131\uc744 \ucd94\uac00\ud558\ub294 \ubc29\ubc95\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\n", "\n", "<div class=\"admonition tip\">\n", "    <p class=\"admonition-title\">\ucc38\uace0</p>\n", "    <p>\n", "        \uc5ec\ub7ec \ub300\ud654\ub098 \uc0ac\uc6a9\uc790 \uac04\uc5d0 <b>\uacf5\uc720</b>\ub418\ub294 \uba54\ubaa8\ub9ac\uac00 \ud544\uc694\ud558\ub2e4\uba74 (\ud06c\ub85c\uc2a4 \uc2a4\ub808\ub4dc \uc9c0\uc18d\uc131), \uc774 <a href=\"https://langchain-ai.github.io/langgraph/how-tos/cross-thread-persistence/\">\ud558\uc6b0\ud22c \uac00\uc774\ub4dc</a>\ub97c \ud655\uc778\ud558\uc138\uc694.\n", "    </p>\n", "</div>\n"]}, {"cell_type": "markdown", "id": "7cbd446a-808f-4394-be92-d45ab818953c", "metadata": {}, "source": ["## \uc124\uc815\n", "\n", "\uba3c\uc800 \ud544\uc694\ud55c \ud328\ud0a4\uc9c0\ub97c \uc124\uce58\ud574\uc57c \ud569\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 1, "id": "af4ce0ba-7596-4e5f-8bf8-0b0bd6e62833", "metadata": {}, "outputs": [], "source": ["%%capture --no-stderr\n", "%pip install --quiet -U langgraph langchain_anthropic\n"]}, {"cell_type": "markdown", "id": "0abe11f4-62ed-4dc4-8875-3db21e260d1d", "metadata": {}, "source": ["\ub2e4\uc74c\uc73c\ub85c, \uc0ac\uc6a9\ud560 LLM\uc778 Anthropic\uc758 API \ud0a4\ub97c \uc124\uc815\ud574\uc57c \ud569\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 2, "id": "c903a1cf-2977-4e2d-ad7d-8b3946821d89", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["ANTHROPIC_API_KEY:  \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"]}], "source": ["import getpass\n", "import os\n", "\n", "\n", "def _set_env(var: str):\n", "    if not os.environ.get(var):\n", "        os.environ[var] = getpass.getpass(f\"{var}: \")\n", "\n", "\n", "_set_env(\"ANTHROPIC_API_KEY\")\n"]}, {"cell_type": "markdown", "id": "f0ed46a8-effe-4596-b0e1-a6a29ee16f5c", "metadata": {}, "source": ["<div class=\"admonition tip\">\n", "    <p class=\"admonition-title\">LangGraph \uac1c\ubc1c\uc744 \uc704\ud55c <a href=\"https://smith.langchain.com\">LangSmith</a> \uc124\uc815</p>\n", "    <p style=\"padding-top: 5px;\">\n", "        LangSmith\uc5d0 \uac00\uc785\ud558\uc5ec LangGraph \ud504\ub85c\uc81d\ud2b8\uc758 \ubb38\uc81c\ub97c \uc2e0\uc18d\ud558\uac8c \ud30c\uc545\ud558\uace0 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\uc138\uc694. LangSmith\ub97c \uc0ac\uc6a9\ud558\uba74 LangGraph\ub85c \uad6c\ucd95\ub41c LLM \uc571\uc744 \ub514\ubc84\uadf8, \ud14c\uc2a4\ud2b8 \ubc0f \ubaa8\ub2c8\ud130\ub9c1\ud558\ub294 \ub370 \ud544\uc694\ud55c \ucd94\uc801 \ub370\uc774\ud130\ub97c \ud65c\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc0ac\uc6a9\uc744 \uc2dc\uc791\ud558\ub294 \ubc29\ubc95\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 <a href=\"https://docs.smith.langchain.com\">\uc5ec\uae30</a>\ub97c \ucc38\uc870\ud558\uc138\uc694. \n", "    </p>\n", "</div>\n"]}, {"cell_type": "markdown", "id": "4cf509bc", "metadata": {}, "source": ["## \uadf8\ub798\ud504 \uc815\uc758\n", "\n", "\uc6b0\ub9ac\ub294 [\ucc57 \ubaa8\ub378](https://python.langchain.com/docs/concepts/#chat-models)\uc744 \ud638\ucd9c\ud558\ub294 \ub2e8\uc77c \ub178\ub4dc \uadf8\ub798\ud504\ub97c \uc0ac\uc6a9\ud560 \uac83\uc785\ub2c8\ub2e4.\n", "\n", "\uba3c\uc800 \uc6b0\ub9ac\uac00 \uc0ac\uc6a9\ud560 \ubaa8\ub378\uc744 \uc815\uc758\ud558\uaca0\uc2b5\ub2c8\ub2e4:\n"]}, {"cell_type": "code", "execution_count": 3, "id": "892b54b9-75f0-4804-9ed0-88b5e5532989", "metadata": {}, "outputs": [], "source": ["from langchain_anthropic import ChatAnthropic\n", "\n", "model = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n"]}, {"cell_type": "markdown", "id": "7b7a2792-982b-4e47-83eb-0c594725d1c1", "metadata": {}, "source": ["\uc774\uc81c `StateGraph`\ub97c \uc815\uc758\ud558\uace0 \ubaa8\ub378 \ud638\ucd9c \ub178\ub4dc\ub97c \ucd94\uac00\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4:\n"]}, {"cell_type": "code", "execution_count": 4, "id": "87326ea6-34c5-46da-a41f-dda26ef9bd74", "metadata": {}, "outputs": [], "source": ["from typing import Annotated\n", "from typing_extensions import TypedDict\n", "\n", "from langgraph.graph import StateGraph, MessagesState, START\n", "\n", "\n", "def call_model(state: MessagesState):\n", "    response = model.invoke(state[\"messages\"])\n", "    return {\"messages\": response}\n", "\n", "\n", "builder = StateGraph(MessagesState)\n", "builder.add_node(\"call_model\", call_model)\n", "builder.add_edge(START, \"call_model\")\n", "graph = builder.compile()\n"]}, {"cell_type": "markdown", "id": "250d8fd9-2e7a-4892-9adc-19762a1e3cce", "metadata": {}, "source": ["\uc774 \uadf8\ub798\ud504\ub97c \uc0ac\uc6a9\ud558\ub824\uace0 \ud558\uba74 \ub300\ud654\uc758 \ub9e5\ub77d\uc774 \uc0c1\ud638\uc791\uc6a9 \uac04\uc5d0 \uc720\uc9c0\ub418\uc9c0 \uc54a\uc744 \uac83\uc785\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 5, "id": "6fa9a5e3-7101-43ab-a811-592e222b9580", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["================================\u001b[1m Human Message \u001b[0m=================================\n", "\n", "hi! I'm bob\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "\n", "Hello Bob! It's nice to meet you. How are you doing today? Is there anything I can help you with or would you like to chat about something in particular?\n", "================================\u001b[1m Human Message \u001b[0m=================================\n", "\n", "what's my name?\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "\n", "I apologize, but I don't have access to your personal information, including your name. I'm an AI language model designed to provide general information and answer questions to the best of my ability based on my training data. I don't have any information about individual users or their personal details. If you'd like to share your name, you're welcome to do so, but I won't be able to recall it in future conversations.\n"]}], "source": ["input_message = {\"role\": \"user\", \"content\": \"hi! I'm bob\"}\n", "for chunk in graph.stream({\"messages\": [input_message]}, stream_mode=\"values\"):\n", "    chunk[\"messages\"][-1].pretty_print()\n", "\n", "input_message = {\"role\": \"user\", \"content\": \"what's my name?\"}\n", "for chunk in graph.stream({\"messages\": [input_message]}, stream_mode=\"values\"):\n", "    chunk[\"messages\"][-1].pretty_print()\n"]}, {"cell_type": "markdown", "id": "bc9c8536-f90b-44fa-958d-5df016c66d8f", "metadata": {}, "source": ["## \uc9c0\uc18d\uc131 \ucd94\uac00\n", "\n", "\uc9c0\uc18d\uc131\uc744 \ucd94\uac00\ud558\ub824\uba74 \uadf8\ub798\ud504\ub97c \ucef4\ud30c\uc77c\ud560 \ub54c [\uccb4\ud06c\ud3ec\uc778\ud130](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.base.BaseCheckpointSaver)\ub97c \uc804\ub2ec\ud574\uc57c \ud569\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 6, "id": "f088933f-264c-477f-9a7d-03f6e9d4ee3a", "metadata": {}, "outputs": [], "source": ["from langgraph.checkpoint.memory import MemorySaver\n", "\n", "memory = MemorySaver()\n", "graph = builder.compile(checkpointer=memory)\n", "# If you're using LangGraph Cloud or LangGraph Studio, you don't need to pass the checkpointer when compiling the graph, since it's done automatically.\n"]}, {"cell_type": "markdown", "id": "7654ebcc-2179-41b4-92d1-6666f6f8634f", "metadata": {}, "source": ["<div class=\"admonition tip\">\n", "    <p class=\"admonition-title\">\ucc38\uace0</p>\n", "    <p>\n", "        LangGraph Cloud \ub610\ub294 LangGraph Studio\ub97c \uc0ac\uc6a9\ud558\uace0 \uc788\ub2e4\uba74, \uadf8\ub798\ud504\ub97c \ucef4\ud30c\uc77c\ud560 \ub54c \uccb4\ud06c\ud3ec\uc778\ud130\ub97c \uc804\ub2ec\ud560 \ud544\uc694\uac00 <strong>\uc5c6\uc2b5\ub2c8\ub2e4</strong>, \uc774\uc720\ub294 \uc790\ub3d9\uc73c\ub85c \ucc98\ub9ac\ub418\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4.\n", "    </p>\n", "</div>\n"]}, {"cell_type": "markdown", "id": "2a1b56c5-bd61-4192-8bdb-458a1e9f0159", "metadata": {}, "source": ["\uc774\uc81c \uc5d0\uc774\uc804\ud2b8\uc640 \uc0c1\ud638\uc791\uc6a9\ud560 \uc218 \uc788\uc73c\uba70, \uc774\uc804 \uba54\uc2dc\uc9c0\ub97c \uae30\uc5b5\ud558\uace0 \uc788\uc74c\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4!\n"]}, {"cell_type": "code", "execution_count": 7, "id": "cfd140f0-a5a6-4697-8115-322242f197b5", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["================================\u001b[1m Human Message \u001b[0m=================================\n", "\n", "hi! I'm bob\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "\n", "Hello Bob! It's nice to meet you. How are you doing today? Is there anything in particular you'd like to chat about or any questions you have that I can help you with?\n"]}], "source": ["config = {\"configurable\": {\"thread_id\": \"1\"}}\n", "input_message = {\"role\": \"user\", \"content\": \"hi! I'm bob\"}\n", "for chunk in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n", "    chunk[\"messages\"][-1].pretty_print()\n"]}, {"cell_type": "markdown", "id": "1bb07bf8-68b7-4049-a0f1-eb67a4879a3a", "metadata": {}, "source": ["\uc774\uc804 \ub300\ud654\ub97c \ud56d\uc0c1 \uc7ac\uac1c\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4:\n"]}, {"cell_type": "code", "execution_count": 8, "id": "08ae8246-11d5-40e1-8567-361e5bef8917", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["================================\u001b[1m Human Message \u001b[0m=================================\n", "\n", "what's my name?\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "\n", "Your name is Bob, as you introduced yourself at the beginning of our conversation.\n"]}], "source": ["input_message = {\"role\": \"user\", \"content\": \"what's my name?\"}\n", "for chunk in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n", "    chunk[\"messages\"][-1].pretty_print()\n"]}, {"cell_type": "markdown", "id": "3f47bbfc-d9ef-4288-ba4a-ebbc0136fa9d", "metadata": {}, "source": ["\uc0c8\ub85c\uc6b4 \ub300\ud654\ub97c \uc2dc\uc791\ud558\uace0 \uc2f6\ub2e4\uba74, \ub2e4\ub978 `thread_id`\ub97c \uc804\ub2ec\ud558\uba74 \ub429\ub2c8\ub2e4. \ubfc5! \ubaa8\ub4e0 \uae30\uc5b5\uc774 \uc0ac\ub77c\uc9d1\ub2c8\ub2e4!\n"]}, {"cell_type": "code", "execution_count": 9, "id": "273d56a8-f40f-4a51-a27f-7c6bb2bda0ba", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["================================\u001b[1m Human Message \u001b[0m=================================\n", "\n", "what's is my name?\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "\n", "I apologize, but I don't have access to your personal information, including your name. As an AI language model, I don't have any information about individual users unless it's provided within the conversation. If you'd like to share your name, you're welcome to do so, but otherwise, I won't be able to know or guess it.\n"]}], "source": ["input_message = {\"role\": \"user\", \"content\": \"what's my name?\"}\n", "for chunk in graph.stream(\n", "    {\"messages\": [input_message]},\n", "    {\"configurable\": {\"thread_id\": \"2\"}},\n", "    stream_mode=\"values\",\n", "):\n", "    chunk[\"messages\"][-1].pretty_print()\n"]}], "metadata": {}}