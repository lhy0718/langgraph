{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ub3c4\uad6c \ud638\ucd9c \uac80\ud1a0 \ubc29\ubc95 (\uae30\ub2a5\uc801 API)\n", "\n", "!!! \uc815\ubcf4 \"\uc0ac\uc804 \uc694\uad6c \uc0ac\ud56d\"\n", "    \uc774 \uac00\uc774\ub4dc\ub294 \ub2e4\uc74c\uc5d0 \ub300\ud55c \uc774\ud574\ub97c \uc804\uc81c\ub85c \ud569\ub2c8\ub2e4:\n", "\n", "    - [\uc778\uac04-\uc21c\ud658](../../concepts/human_in_the_loop) \uc6cc\ud06c\ud50c\ub85c\uc6b0 \uad6c\ud604 [\uc778\ud130\ub7fd\ud2b8](../../concepts/human_in_the_loop/#interrupt) \uc0ac\uc6a9\n", "    - [\uae30\ub2a5\uc801 API\ub97c \uc0ac\uc6a9\ud558\uc5ec ReAct \uc5d0\uc774\uc804\ud2b8 \uc0dd\uc131 \ubc29\ubc95](../../how-tos/react-agent-from-scratch-functional)\n", "\n", "\uc774 \uac00\uc774\ub4dc\ub294 LangGraph [\uae30\ub2a5\uc801 API](../../concepts/functional_api)\ub97c \uc0ac\uc6a9\ud558\uc5ec ReAct \uc5d0\uc774\uc804\ud2b8\uc5d0\uc11c \uc778\uac04-\uc21c\ud658 \uc6cc\ud06c\ud50c\ub85c\uc6b0\ub97c \uad6c\ud604\ud558\ub294 \ubc29\ubc95\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\n", "\n", "\uc6b0\ub9ac\ub294 [\uae30\ub2a5\uc801 API\ub97c \uc0ac\uc6a9\ud558\uc5ec ReAct \uc5d0\uc774\uc804\ud2b8\ub97c \uc0dd\uc131\ud558\ub294 \ubc29\ubc95](../../how-tos/react-agent-from-scratch-functional) \uac00\uc774\ub4dc\uc5d0\uc11c \uc0dd\uc131\ub41c \uc5d0\uc774\uc804\ud2b8\ub97c \uae30\ubc18\uc73c\ub85c \uc791\uc5c5\ud560 \uac83\uc785\ub2c8\ub2e4.\n", "\n", "\ud2b9\ud788, \uc6b0\ub9ac\ub294 [\ucc44\ud305 \ubaa8\ub378](https://python.langchain.com/docs/concepts/chat_models/)\uc5d0 \uc758\ud574 \uc0dd\uc131\ub41c [\ub3c4\uad6c \ud638\ucd9c](https://python.langchain.com/docs/concepts/tool_calling/)\uc744 \uc2e4\ud589\ud558\uae30 \uc804\uc5d0 \uac80\ud1a0\ud558\ub294 \ubc29\ubc95\uc744 \ubcf4\uc5ec\uc904 \uac83\uc785\ub2c8\ub2e4. \uc774\ub294 \uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc758 \uc8fc\uc694 \ud3ec\uc778\ud2b8\uc5d0\uc11c [\uc778\ud130\ub7fd\ud2b8](../../concepts/human_in_the_loop/#interrupt) \uae30\ub2a5\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc218\ud589\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n", "\n", "**\ubbf8\ub9ac \ubcf4\uae30**:\n", "\n", "\uc6b0\ub9ac\ub294 \ucc44\ud305 \ubaa8\ub378\uc5d0\uc11c \uc0dd\uc131\ub41c \ub3c4\uad6c \ud638\ucd9c\uc744 \uac80\ud1a0\ud558\ub294 \uac04\ub2e8\ud55c \ud568\uc218\ub97c \uad6c\ud604\ud558\uace0 \uc774\ub97c \uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc758 [\uc5d4\ud2b8\ub9ac\ud3ec\uc778\ud2b8](../../concepts/functional_api/#entrypoint) \ub0b4\ubd80\uc5d0\uc11c \ud638\ucd9c\ud560 \uac83\uc785\ub2c8\ub2e4:\n", "\n", "```python\n", "def review_tool_call(tool_call: ToolCall) -> Union[ToolCall, ToolMessage]:\n", "    \"\"\"\ub3c4\uad6c \ud638\ucd9c\uc744 \uac80\ud1a0\ud558\uace0 \uac80\uc99d\ub41c \ubc84\uc804\uc744 \ubc18\ud658\ud569\ub2c8\ub2e4.\"\"\"\n", "    human_review = interrupt(\n", "        {\n", "            \"question\": \"\uc774\uac83\uc774 \uc62c\ubc14\ub978\uac00\uc694?\",\n", "            \"tool_call\": tool_call,\n", "        }\n", "    )\n", "    review_action = human_review[\"action\"]\n", "    review_data = human_review.get(\"data\")\n", "    if review_action == \"continue\":\n", "        return tool_call\n", "    elif review_action == \"update\":\n", "        updated_tool_call = {**tool_call, **{\"args\": review_data}}\n", "        return updated_tool_call\n", "    elif review_action == \"feedback\":\n", "        return ToolMessage(\n", "            content=review_data, name=tool_call[\"name\"], tool_call_id=tool_call[\"id\"]\n", "        )\n", "```\n", "\n", "## \uc124\uc815\n", "\n", "\uba3c\uc800, \ud544\uc694\ud55c \ud328\ud0a4\uc9c0\ub97c \uc124\uce58\ud558\uace0 API \ud0a4\ub97c \uc124\uc815\ud569\uc2dc\ub2e4:\n"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["%%capture --no-stderr\n", "%pip install -U langgraph langchain-openai\n"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["import getpass\n", "import os\n", "\n", "\n", "def _set_env(var: str):\n", "    if not os.environ.get(var):\n", "        os.environ[var] = getpass.getpass(f\"{var}: \")\n", "\n", "\n", "_set_env(\"OPENAI_API_KEY\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"admonition tip\">\n", "     <p class=\"admonition-title\">\ub354 \ub098\uc740 \ub514\ubc84\uae45\uc744 \uc704\ud574 <a href=\"https://smith.langchain.com\">LangSmith</a> \uc124\uc815\ud558\uae30</p>\n", "     <p style=\"padding-top: 5px;\">\n", "         LangSmith\uc5d0 \uac00\uc785\ud558\uc5ec \ubb38\uc81c\ub97c \ube60\ub974\uac8c \ubc1c\uacac\ud558\uace0 LangGraph \ud504\ub85c\uc81d\ud2b8\uc758 \uc131\ub2a5\uc744 \uac1c\uc120\ud558\uc138\uc694. LangSmith\ub294 LangGraph\ub85c \ub9cc\ub4e0 LLM \uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc744 \ub514\ubc84\uae45, \ud14c\uc2a4\ud2b8 \ubc0f \ubaa8\ub2c8\ud130\ub9c1\ud558\uae30 \uc704\ud574 \ucd94\uc801 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud560 \uc218 \uc788\uac8c \ud574\uc90d\ub2c8\ub2e4 \u2014 \uc2dc\uc791\ud558\ub294 \ubc29\ubc95\uc5d0 \ub300\ud574\uc11c\ub294 <a href=\"https://docs.smith.langchain.com\">\ubb38\uc11c</a>\ub97c \uc77d\uc5b4\ubcf4\uc138\uc694.\n", "     </p>\n", " </div>\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ubaa8\ub378 \ubc0f \ub3c4\uad6c \uc815\uc758\n", "\n", "\uba3c\uc800 \uc608\uc81c\ub97c \uc704\ud574 \uc0ac\uc6a9\ud560 \ub3c4\uad6c\uc640 \ubaa8\ub378\uc744 \uc815\uc758\ud569\uc2dc\ub2e4. [ReAct \uc5d0\uc774\uc804\ud2b8 \uac00\uc774\ub4dc](../../how-tos/react-agent-from-scratch-functional)\uc640 \uac19\uc774, \uc6b0\ub9ac\ub294 \uc704\uce58\uc5d0 \ub300\ud55c \ub0a0\uc528 \uc124\uba85\uc744 \uc5bb\ub294 \ub2e8\uc77c \ud50c\ub808\uc774\uc2a4\ud640\ub354 \ub3c4\uad6c\ub97c \uc0ac\uc6a9\ud560 \uac83\uc785\ub2c8\ub2e4.\n", "\n", "\uc774\ubc88 \uc608\uc81c\uc5d0\uc11c\ub294 [OpenAI](https://python.langchain.com/docs/integrations/providers/openai/) \ucc44\ud305 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud560 \uac83\uc774\uc9c0\ub9cc, \ub3c4\uad6c \ud638\ucd9c\uc744 \uc9c0\uc6d0\ud558\ub294 \uc5b4\ub5a4 \ubaa8\ub378\ub3c4 [\uc0ac\uc6a9\ud560 \uc218](https://python.langchain.com/docs/integrations/chat/) \uc788\uc2b5\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["from langchain_openai import ChatOpenAI\n", "from langchain_core.tools import tool\n", "\n", "model = ChatOpenAI(model=\"gpt-4o-mini\")\n", "\n", "\n", "@tool\n", "def get_weather(location: str):\n", "    \"\"\"Call to get the weather from a specific location.\"\"\"\n", "    # This is a placeholder for the actual implementation\n", "    if any([city in location.lower() for city in [\"sf\", \"san francisco\"]]):\n", "        return \"It's sunny!\"\n", "    elif \"boston\" in location.lower():\n", "        return \"It's rainy!\"\n", "    else:\n", "        return f\"I am not sure what the weather is in {location}\"\n", "\n", "\n", "tools = [get_weather]\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \uc791\uc5c5 \uc815\uc758\n", "\n", "\uc6b0\ub9ac\uc758 [\uc791\uc5c5](../../concepts/functional_api/#task)\uc740 [ReAct \uc5d0\uc774\uc804\ud2b8 \uac00\uc774\ub4dc](../../how-tos/react-agent-from-scratch-functional)\uc640 \ubcc0\uacbd\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4:\n", "\n", "1. **\ubaa8\ub378 \ud638\ucd9c**: \uc6b0\ub9ac\ub294 \uba54\uc2dc\uc9c0 \ubaa9\ub85d\uc73c\ub85c \uc6b0\ub9ac\uc758 \ucc44\ud305 \ubaa8\ub378\uc5d0 \ucffc\ub9ac\ud558\uace0\uc790 \ud569\ub2c8\ub2e4.\n", "2. **\ub3c4\uad6c \ud638\ucd9c**: \ub9cc\uc57d \uc6b0\ub9ac\uc758 \ubaa8\ub378\uc774 \ub3c4\uad6c \ud638\ucd9c\uc744 \uc0dd\uc131\ud55c\ub2e4\uba74, \uc6b0\ub9ac\ub294 \uc774\ub97c \uc2e4\ud589\ud558\uace0\uc790 \ud569\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["from langchain_core.messages import ToolCall, ToolMessage\n", "from langgraph.func import entrypoint, task\n", "\n", "\n", "tools_by_name = {tool.name: tool for tool in tools}\n", "\n", "\n", "@task\n", "def call_model(messages):\n", "    \"\"\"Call model with a sequence of messages.\"\"\"\n", "    response = model.bind_tools(tools).invoke(messages)\n", "    return response\n", "\n", "\n", "@task\n", "def call_tool(tool_call):\n", "    tool = tools_by_name[tool_call[\"name\"]]\n", "    observation = tool.invoke(tool_call[\"args\"])\n", "    return ToolMessage(content=observation, tool_call_id=tool_call[\"id\"])\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \uc5d4\ud2b8\ub9ac\ud3ec\uc778\ud2b8 \uc815\uc758\n", "\n", "\uc2e4\ud589 \uc804\uc5d0 \ub3c4\uad6c \ud638\ucd9c\uc744 \uac80\ud1a0\ud558\uae30 \uc704\ud574, \uc6b0\ub9ac\ub294 `review_tool_call` \ud568\uc218\ub97c \ucd94\uac00\ud558\uc5ec [interrupt](../../concepts/human_in_the_loop/#interrupt)\ub97c \ud638\ucd9c\ud569\ub2c8\ub2e4. \uc774 \ud568\uc218\uac00 \ud638\ucd9c\ub418\uba74, \uc7ac\uac1c \uba85\ub839\uc744 \ub0b4\ub9b4 \ub54c\uae4c\uc9c0 \uc2e4\ud589\uc774 \uc77c\uc2dc \uc911\uc9c0\ub429\ub2c8\ub2e4.\n", "\n", "\uc8fc\uc5b4\uc9c4 \ub3c4\uad6c \ud638\ucd9c\uc5d0 \ub300\ud574, \uc6b0\ub9ac\uc758 \ud568\uc218\ub294 \uc778\uac04 \uac80\ud1a0\ub97c \uc704\ud574 `interrupt`\ub97c \uc218\ud589\ud569\ub2c8\ub2e4. \uadf8 \uc2dc\uc810\uc5d0\uc11c \uc6b0\ub9ac\ub294 \ub2e4\uc74c\uc744 \uc218\ud589\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4:\n", "\n", "- \ub3c4\uad6c \ud638\ucd9c\uc744 \uc218\ub77d\ud569\ub2c8\ub2e4;\n", "- \ub3c4\uad6c \ud638\ucd9c\uc744 \uc218\uc815\ud558\uace0 \uacc4\uc18d \uc9c4\ud589\ud569\ub2c8\ub2e4;\n", "- \uc0ac\uc6a9\uc790 \uc9c0\uc815 \ub3c4\uad6c \uba54\uc2dc\uc9c0\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4 (\uc608: \ubaa8\ub378\uc5d0\uac8c \ub3c4\uad6c \ud638\ucd9c \ud615\uc2dd\uc744 \ub2e4\uc2dc \uc9c0\uc815\ud558\ub3c4\ub85d \uc9c0\uc2dc\ud558\ub294 \uacbd\uc6b0).\n", "\n", "\uc544\ub798\uc758 [\uc0ac\uc6a9 \uc608\uc2dc](#usage)\uc5d0\uc11c \uc774 \uc138 \uac00\uc9c0 \uc0ac\ub840\ub97c \ubcf4\uc5ec\uc904 \uac83\uc785\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["from typing import Union\n", "\n", "\n", "def review_tool_call(tool_call: ToolCall) -> Union[ToolCall, ToolMessage]:\n", "    \"\"\"Review a tool call, returning a validated version.\"\"\"\n", "    human_review = interrupt(\n", "        {\n", "            \"question\": \"Is this correct?\",\n", "            \"tool_call\": tool_call,\n", "        }\n", "    )\n", "    review_action = human_review[\"action\"]\n", "    review_data = human_review.get(\"data\")\n", "    if review_action == \"continue\":\n", "        return tool_call\n", "    elif review_action == \"update\":\n", "        updated_tool_call = {**tool_call, **{\"args\": review_data}}\n", "        return updated_tool_call\n", "    elif review_action == \"feedback\":\n", "        return ToolMessage(\n", "            content=review_data, name=tool_call[\"name\"], tool_call_id=tool_call[\"id\"]\n", "        )\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\uc774\uc81c \uc0dd\uc131\ub41c \ub3c4\uad6c \ud638\ucd9c\uc744 \uac80\ud1a0\ud558\uae30 \uc704\ud574 [\uc9c4\uc785\uc810](../../concepts/functional_api/#entrypoint)\uc744 \uc5c5\ub370\uc774\ud2b8\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ub3c4\uad6c \ud638\ucd9c\uc774 \uc218\ub77d\ub418\uac70\ub098 \uc218\uc815\ub418\uba74 \uc774\uc804\uacfc \ub3d9\uc77c\ud55c \ubc29\uc2dd\uc73c\ub85c \uc2e4\ud589\ud569\ub2c8\ub2e4. \uadf8\ub807\uc9c0 \uc54a\uc73c\uba74 \uc778\uac04\uc774 \uc81c\uacf5\ud55c `ToolMessage`\ub97c \uadf8\ub0e5 \ucd94\uac00\ud569\ub2c8\ub2e4.\n", "\n", "!!! \ud301\n", "\n", "    \uc774\uc804 \uc791\uc5c5\uc758 \uacb0\uacfc \u2014 \uc774 \uacbd\uc6b0 \ucd08\uae30 \ubaa8\ub378 \ud638\ucd9c \u2014 \ub294 \uc9c0\uc18d\ub418\uc5b4 `interrupt` \uc774\ud6c4\uc5d0 \ub2e4\uc2dc \uc2e4\ud589\ub418\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["from langgraph.checkpoint.memory import MemorySaver\n", "from langgraph.graph.message import add_messages\n", "from langgraph.types import Command, interrupt\n", "\n", "\n", "checkpointer = MemorySaver()\n", "\n", "\n", "@entrypoint(checkpointer=checkpointer)\n", "def agent(messages, previous):\n", "    if previous is not None:\n", "        messages = add_messages(previous, messages)\n", "\n", "    llm_response = call_model(messages).result()\n", "    while True:\n", "        if not llm_response.tool_calls:\n", "            break\n", "\n", "        # Review tool calls\n", "        tool_results = []\n", "        tool_calls = []\n", "        for i, tool_call in enumerate(llm_response.tool_calls):\n", "            review = review_tool_call(tool_call)\n", "            if isinstance(review, ToolMessage):\n", "                tool_results.append(review)\n", "            else:  # is a validated tool call\n", "                tool_calls.append(review)\n", "                if review != tool_call:\n", "                    llm_response.tool_calls[i] = review  # update message\n", "\n", "        # Execute remaining tool calls\n", "        tool_result_futures = [call_tool(tool_call) for tool_call in tool_calls]\n", "        remaining_tool_results = [fut.result() for fut in tool_result_futures]\n", "\n", "        # Append to message list\n", "        messages = add_messages(\n", "            messages,\n", "            [llm_response, *tool_results, *remaining_tool_results],\n", "        )\n", "\n", "        # Call model again\n", "        llm_response = call_model(messages).result()\n", "\n", "    # Generate final response\n", "    messages = add_messages(messages, llm_response)\n", "    return entrypoint.final(value=llm_response, save=messages)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### \uc0ac\uc6a9 \uc608\uc2dc\n", "\n", "\uba87 \uac00\uc9c0 \uc2dc\ub098\ub9ac\uc624\ub97c \ubcf4\uc5ec\ub4dc\ub9ac\uaca0\uc2b5\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["def _print_step(step: dict) -> None:\n", "    for task_name, result in step.items():\n", "        if task_name == \"agent\":\n", "            continue  # just stream from tasks\n", "        print(f\"\\n{task_name}:\")\n", "        if task_name in (\"__interrupt__\", \"review_tool_call\"):\n", "            print(result)\n", "        else:\n", "            result.pretty_print()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### \ub3c4\uad6c \ud638\ucd9c \uc218\ub77d\ud558\uae30\n", "\n", "\ub3c4\uad6c \ud638\ucd9c\uc744 \uc218\ub77d\ud558\uae30 \uc704\ud574, \uc6b0\ub9ac\uac00 `Command`\uc5d0\uc11c \uc81c\uacf5\ud558\ub294 \ub370\uc774\ud130\uc5d0 \ub3c4\uad6c \ud638\ucd9c\uc774 \ud1b5\uacfc\ud574\uc57c \ud55c\ub2e4\uace0 \ud45c\uc2dc\ud558\uae30\ub9cc \ud558\uba74 \ub429\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["config = {\"configurable\": {\"thread_id\": \"1\"}}\n"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'role': 'user', 'content': \"What's the weather in san francisco?\"}\n", "\n", "call_model:\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "Tool Calls:\n", "  get_weather (call_Bh5cSwMqCpCxTjx7AjdrQTPd)\n", " Call ID: call_Bh5cSwMqCpCxTjx7AjdrQTPd\n", "  Args:\n", "    location: San Francisco\n", "\n", "__interrupt__:\n", "(Interrupt(value={'question': 'Is this correct?', 'tool_call': {'name': 'get_weather', 'args': {'location': 'San Francisco'}, 'id': 'call_Bh5cSwMqCpCxTjx7AjdrQTPd', 'type': 'tool_call'}}, resumable=True, ns=['agent:22fcc9cd-3573-b39b-eea7-272a025903e2'], when='during'),)\n"]}], "source": ["user_message = {\"role\": \"user\", \"content\": \"What's the weather in san francisco?\"}\n", "print(user_message)\n", "\n", "for step in agent.stream([user_message], config):\n", "    _print_step(step)\n"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "call_tool:\n", "=================================\u001b[1m Tool Message \u001b[0m=================================\n", "\n", "It's sunny!\n", "\n", "call_model:\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "\n", "The weather in San Francisco is sunny!\n"]}], "source": ["# highlight-next-line\n", "human_input = Command(resume={\"action\": \"continue\"})\n", "\n", "for step in agent.stream(human_input, config):\n", "    _print_step(step)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### \ub3c4\uad6c \ud638\ucd9c \uc218\uc815\n", "\n", "\ub3c4\uad6c \ud638\ucd9c\uc744 \uc218\uc815\ud558\ub824\uba74 \uc5c5\ub370\uc774\ud2b8\ub41c \uc778\uc218\ub97c \uc81c\uacf5\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": ["config = {\"configurable\": {\"thread_id\": \"2\"}}\n"]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'role': 'user', 'content': \"What's the weather in san francisco?\"}\n", "\n", "call_model:\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "Tool Calls:\n", "  get_weather (call_b9h8e18FqH0IQm3NMoeYKz6N)\n", " Call ID: call_b9h8e18FqH0IQm3NMoeYKz6N\n", "  Args:\n", "    location: san francisco\n", "\n", "__interrupt__:\n", "(Interrupt(value={'question': 'Is this correct?', 'tool_call': {'name': 'get_weather', 'args': {'location': 'san francisco'}, 'id': 'call_b9h8e18FqH0IQm3NMoeYKz6N', 'type': 'tool_call'}}, resumable=True, ns=['agent:9559a81d-5720-dc19-a457-457bac7bdd83'], when='during'),)\n"]}], "source": ["user_message = {\"role\": \"user\", \"content\": \"What's the weather in san francisco?\"}\n", "print(user_message)\n", "\n", "for step in agent.stream([user_message], config):\n", "    _print_step(step)\n"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "call_tool:\n", "=================================\u001b[1m Tool Message \u001b[0m=================================\n", "\n", "It's sunny!\n", "\n", "call_model:\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "\n", "The weather in San Francisco is sunny!\n"]}], "source": ["# highlight-next-line\n", "human_input = Command(resume={\"action\": \"update\", \"data\": {\"location\": \"SF, CA\"}})\n", "\n", "for step in agent.stream(human_input, config):\n", "    _print_step(step)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\uc774\ubc88 \uc2e4\ud589\uc758 LangSmith \ucd94\uc801\uc740 \ud2b9\ud788 \uc720\uc775\ud569\ub2c8\ub2e4:\n", "\n", "- [\uc911\ub2e8 \uc804](https://smith.langchain.com/public/c8b07579-5cf4-4adb-a849-282163bc9d99/r/b5b128d6-e715-480b-b58d-59e64f724275) \ucd94\uc801\uc5d0\uc11c, \uc6b0\ub9ac\ub294 \uc704\uce58 `\"\uc0cc\ud504\ub780\uc2dc\uc2a4\ucf54\"`\uc5d0 \ub300\ud55c \ub3c4\uad6c \ud638\ucd9c\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4.\n", "- [\uc7ac\uac1c \ud6c4](https://smith.langchain.com/public/b28b92e5-a555-482d-aa4d-c675a19f0eb5/r) \ucd94\uc801\uc5d0\uc11c\ub294 \uba54\uc2dc\uc9c0\uc758 \ub3c4\uad6c \ud638\ucd9c\uc774 `\"SF, CA\"`\ub85c \uc5c5\ub370\uc774\ud2b8\ub41c \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### \uc0ac\uc6a9\uc790 \uc9c0\uc815 ToolMessage \uc0dd\uc131\n", "\n", "\uc0ac\uc6a9\uc790 \uc9c0\uc815 `ToolMessage`\ub97c \uc0dd\uc131\ud558\uae30 \uc704\ud574, \uba54\uc2dc\uc9c0\uc758 \ub0b4\uc6a9\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4. \uc774 \uacbd\uc6b0 \ubaa8\ub378\uc5d0 \ub3c4\uad6c \ud638\ucd9c\uc758 \ud615\uc2dd\uc744 \ub2e4\uc2dc \uc870\uc815\ud558\ub3c4\ub85d \uc694\uccad\ud560 \uac83\uc785\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [], "source": ["config = {\"configurable\": {\"thread_id\": \"3\"}}\n"]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'role': 'user', 'content': \"What's the weather in san francisco?\"}\n", "\n", "call_model:\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "Tool Calls:\n", "  get_weather (call_VqGjKE7uu8HdWs9XuY1kMV18)\n", " Call ID: call_VqGjKE7uu8HdWs9XuY1kMV18\n", "  Args:\n", "    location: San Francisco\n", "\n", "__interrupt__:\n", "(Interrupt(value={'question': 'Is this correct?', 'tool_call': {'name': 'get_weather', 'args': {'location': 'San Francisco'}, 'id': 'call_VqGjKE7uu8HdWs9XuY1kMV18', 'type': 'tool_call'}}, resumable=True, ns=['agent:4b3b372b-9da3-70be-5c68-3d9317346070'], when='during'),)\n"]}], "source": ["user_message = {\"role\": \"user\", \"content\": \"What's the weather in san francisco?\"}\n", "print(user_message)\n", "\n", "for step in agent.stream([user_message], config):\n", "    _print_step(step)\n"]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "call_model:\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "Tool Calls:\n", "  get_weather (call_xoXkK8Cz0zIpvWs78qnXpvYp)\n", " Call ID: call_xoXkK8Cz0zIpvWs78qnXpvYp\n", "  Args:\n", "    location: San Francisco, CA\n", "\n", "__interrupt__:\n", "(Interrupt(value={'question': 'Is this correct?', 'tool_call': {'name': 'get_weather', 'args': {'location': 'San Francisco, CA'}, 'id': 'call_xoXkK8Cz0zIpvWs78qnXpvYp', 'type': 'tool_call'}}, resumable=True, ns=['agent:4b3b372b-9da3-70be-5c68-3d9317346070'], when='during'),)\n"]}], "source": ["# highlight-next-line\n", "human_input = Command(\n", "    # highlight-next-line\n", "    resume={\n", "        # highlight-next-line\n", "        \"action\": \"feedback\",\n", "        # highlight-next-line\n", "        \"data\": \"Please format as <City>, <State>.\",\n", "        # highlight-next-line\n", "    },\n", "    # highlight-next-line\n", ")\n", "\n", "for step in agent.stream(human_input, config):\n", "    _print_step(step)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\ud55c \ubc88 \uc7ac\ud615\uc2dd\ud654\ub418\uba74, \uc6b0\ub9ac\ub294 \uadf8\uac83\uc744 \ubc1b\uc544\ub4e4\uc77c \uc218 \uc788\uc2b5\ub2c8\ub2e4:\n"]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "call_tool:\n", "=================================\u001b[1m Tool Message \u001b[0m=================================\n", "\n", "It's sunny!\n", "\n", "call_model:\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "\n", "The weather in San Francisco, CA is sunny!\n"]}], "source": ["# highlight-next-line\n", "human_input = Command(resume={\"action\": \"continue\"})\n", "\n", "for step in agent.stream(human_input, config):\n", "    _print_step(step)\n"]}], "metadata": {"translated_ko": true}}