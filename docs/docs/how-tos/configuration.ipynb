{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["_\ud55c\uad6d\uc5b4\ub85c \uae30\uacc4\ubc88\uc5ed\ub428_\n"]}, {"cell_type": "markdown", "id": "6e6a0a39-9a4c-47ae-a238-1a3a847eea5b", "metadata": {}, "source": ["# \uadf8\ub798\ud504\uc5d0 \ub7f0\ud0c0\uc784 \uad6c\uc131\uc744 \ucd94\uac00\ud558\ub294 \ubc29\ubc95\n", "\n", "\ub54c\ub54c\ub85c \ud638\ucd9c\ud560 \ub54c \uc5d0\uc774\uc804\ud2b8\ub97c \uad6c\uc131\ud560 \uc218 \uc788\uae30\ub97c \uc6d0\ud569\ub2c8\ub2e4. \n", "\uc774\uc758 \uc608\ub85c \uc5b4\ub5a4 LLM\uc744 \uc0ac\uc6a9\ud560\uc9c0\ub97c \uad6c\uc131\ud558\ub294 \uacbd\uc6b0\uac00 \uc788\uc2b5\ub2c8\ub2e4.\n", "\uc544\ub798\uc5d0\uc11c\ub294 \uc774\ub97c \uc218\ud589\ud558\ub294 \uc608\uc81c\ub97c \uc0b4\ud3b4\ubd05\ub2c8\ub2e4.\n", "\n", "<div class=\"admonition tip\">\n", "    <p class=\"admonition-title\">\uc804\uc81c \uc870\uac74</p>\n", "    <p>\n", "        \uc774 \uac00\uc774\ub4dc\ub294 \ub2e4\uc74c\uc5d0 \ub300\ud55c \uc774\ud574\ub97c \uc804\uc81c\ub85c \ud569\ub2c8\ub2e4:\n", "        <ul>\n", "            <li>\n", "                <a href=\"https://langchain-ai.github.io/langgraph/concepts/low_level/#state\">\n", "                    LangGraph \uc0c1\ud0dc\n", "                </a>\n", "            </li>\n", "            <li>\n", "                <a href=\"https://python.langchain.com/docs/concepts/#chat-models/\">\n", "                    \ucc44\ud305 \ubaa8\ub378\n", "                </a>\n", "            </li>\n", "        </ul>\n", "    </p>\n", "</div> \n", "\n", "\n", "## \uc124\uc815\n", "\n", "\uba3c\uc800, \ud544\uc694\ud55c \ud328\ud0a4\uc9c0\ub97c \uc124\uce58\ud558\uace0 API \ud0a4\ub97c \uc124\uc815\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 1, "id": "03df6e04", "metadata": {}, "outputs": [], "source": ["%%capture --no-stderr\n", "%pip install -U langgraph langchain_anthropic\n"]}, {"cell_type": "code", "execution_count": 2, "id": "a00c45e0", "metadata": {}, "outputs": [], "source": ["import getpass\n", "import os\n", "\n", "\n", "def _set_env(var: str):\n", "    if not os.environ.get(var):\n", "        os.environ[var] = getpass.getpass(f\"{var}: \")\n", "\n", "\n", "_set_env(\"ANTHROPIC_API_KEY\")\n"]}, {"cell_type": "markdown", "id": "55e8be3b", "metadata": {}, "source": ["<div class=\"admonition tip\">\n", "    <p class=\"admonition-title\">LangGraph \uac1c\ubc1c\uc744 \uc704\ud55c <a href=\"https://smith.langchain.com\">LangSmith</a> \uc124\uc815</p>\n", "    <p style=\"padding-top: 5px;\">\n", "        LangSmith\uc5d0 \uac00\uc785\ud558\uba74 LangGraph \ud504\ub85c\uc81d\ud2b8\uc758 \ubb38\uc81c\ub97c \uc2e0\uc18d\ud558\uac8c \ubc1c\uacac\ud558\uace0 \uc131\ub2a5\uc744 \uac1c\uc120\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. LangSmith\ub294 LangGraph\ub85c \uad6c\ucd95\ub41c LLM \uc571\uc758 \ub514\ubc84\uadf8, \ud14c\uc2a4\ud2b8 \ubc0f \ubaa8\ub2c8\ud130\ub9c1\uc744 \uc704\ud574 \ucd94\uc801 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud560 \uc218 \uc788\uac8c \ud574\uc90d\ub2c8\ub2e4 \u2014 \uc2dc\uc791\ud558\ub294 \ubc29\ubc95\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 <a href=\"https://docs.smith.langchain.com\">\uc5ec\uae30</a>\ub97c \uc77d\uc5b4\ubcf4\uc138\uc694. \n", "    </p>\n", "</div>\n"]}, {"cell_type": "markdown", "id": "df1ff9cf-f8d2-4109-adf9-2adec83f5a95", "metadata": {}, "source": ["## \uadf8\ub798\ud504 \uc815\uc758\n", "\n", "\uba3c\uc800, \uc544\uc8fc \uac04\ub2e8\ud55c \uadf8\ub798\ud504\ub97c \ub9cc\ub4e4\uc5b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 3, "id": "816523d0-0b59-47cf-9f4c-4838024efe22", "metadata": {}, "outputs": [], "source": ["import operator\n", "from typing import Annotated, Sequence\n", "from typing_extensions import TypedDict\n", "\n", "from langchain_anthropic import ChatAnthropic\n", "from langchain_core.messages import BaseMessage, HumanMessage\n", "\n", "from langgraph.graph import END, StateGraph, START\n", "\n", "model = ChatAnthropic(model_name=\"claude-2.1\")\n", "\n", "\n", "class AgentState(TypedDict):\n", "    messages: Annotated[Sequence[BaseMessage], operator.add]\n", "\n", "\n", "def _call_model(state):\n", "    state[\"messages\"]\n", "    response = model.invoke(state[\"messages\"])\n", "    return {\"messages\": [response]}\n", "\n", "\n", "# Define a new graph\n", "builder = StateGraph(AgentState)\n", "builder.add_node(\"model\", _call_model)\n", "builder.add_edge(START, \"model\")\n", "builder.add_edge(\"model\", END)\n", "\n", "graph = builder.compile()\n"]}, {"cell_type": "markdown", "id": "69a1dd47-c5b3-4e04-af56-45682f74d61f", "metadata": {}, "source": ["## \uadf8\ub798\ud504 \uad6c\uc131\ud558\uae30\n", "\n", "\uc88b\uc2b5\ub2c8\ub2e4! \uc774\uc81c \uc0ac\uc6a9\uc790\uac00 \uc5ec\ub7ec \uac1c\uc758 LLM \uc911\uc5d0\uc11c \uc120\ud0dd\ud560 \uc218 \uc788\ub3c4\ub85d \uc774 \uc608\uc81c\ub97c \ud655\uc7a5\ud55c\ub2e4\uace0 \uac00\uc815\ud574\ubd05\uc2dc\ub2e4. \uc6b0\ub9ac\ub294 `configurable` \ud0a4 \uc548\uc5d0 \uc804\ub2ec\ud568\uc73c\ub85c\uc368 \uc774\ub97c \uc27d\uac8c \uad6c\ud604\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \uad6c\uc131\uc740 \uc785\ub825\uc758 \uc77c\ubd80\uac00 \uc544\ub2cc \uc815\ubcf4\ub97c \ud3ec\ud568\ud558\ub3c4\ub85d \ub418\uc5b4 \uc788\uc73c\uba70 (\ub530\ub77c\uc11c \uc0c1\ud0dc\uc758 \uc77c\ubd80\ub85c \ucd94\uc801\ud558\uace0 \uc2f6\uc9c0 \uc54a\uc740 \uc815\ubcf4\uc785\ub2c8\ub2e4).\n"]}, {"cell_type": "code", "execution_count": 4, "id": "c01f1e7c-8e8b-4e26-98f7-56ac225077b4", "metadata": {}, "outputs": [], "source": ["from langchain_openai import ChatOpenAI\n", "from typing import Optional\n", "from langchain_core.runnables.config import RunnableConfig\n", "\n", "openai_model = ChatOpenAI()\n", "\n", "models = {\n", "    \"anthropic\": model,\n", "    \"openai\": openai_model,\n", "}\n", "\n", "\n", "def _call_model(state: AgentState, config: RunnableConfig):\n", "    # Access the config through the configurable key\n", "    model_name = config[\"configurable\"].get(\"model\", \"anthropic\")\n", "    model = models[model_name]\n", "    response = model.invoke(state[\"messages\"])\n", "    return {\"messages\": [response]}\n", "\n", "\n", "# Define a new graph\n", "builder = StateGraph(AgentState)\n", "builder.add_node(\"model\", _call_model)\n", "builder.add_edge(START, \"model\")\n", "builder.add_edge(\"model\", END)\n", "\n", "graph = builder.compile()\n"]}, {"cell_type": "markdown", "id": "7741b75c-55ba-4c78-bbb1-5dc20a210f11", "metadata": {}, "source": ["\uad6c\uc131\uc744 \uc9c0\uc815\ud558\uc9c0 \uc54a\uace0 \ud638\ucd9c\ud558\uba74 \uc6b0\ub9ac\uac00 \uc815\uc758\ud55c \uae30\ubcf8\uac12(Anthropic)\uc744 \uc0ac\uc6a9\ud560 \uac83\uc785\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 5, "id": "ef50f048-fc43-40c0-b713-346408fcf052", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'messages': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}),\n", "  AIMessage(content='Hello!', additional_kwargs={}, response_metadata={'id': 'msg_01WFXkfgK8AvSckLvYYrHshi', 'model': 'claude-2.1', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 10, 'output_tokens': 6}}, id='run-ece54b16-f8fc-4201-8405-b97122edf8d8-0', usage_metadata={'input_tokens': 10, 'output_tokens': 6, 'total_tokens': 16})]}"]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": ["graph.invoke({\"messages\": [HumanMessage(content=\"hi\")]})\n"]}, {"cell_type": "markdown", "id": "f6896b32-9b25-4342-bfd0-29a3d329a06a", "metadata": {}, "source": ["\uc6b0\ub9ac\ub294 \ub610\ud55c \uad6c\uc131\uc73c\ub85c \ud638\ucd9c\ud558\uc5ec \ub2e4\ub978 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\ub3c4\ub85d \ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 6, "id": "f2f7c74b-9fb0-41c6-9728-dcf9d8a3c397", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'messages': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}),\n", "  AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f8331964-d811-4b44-afb8-56c30ade7c15-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17})]}"]}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": ["config = {\"configurable\": {\"model\": \"openai\"}}\n", "graph.invoke({\"messages\": [HumanMessage(content=\"hi\")]}, config=config)\n"]}, {"cell_type": "markdown", "id": "b4c7eaf1-4ee0-42b3-971d-273a108f205f", "metadata": {}, "source": ["\uc6b0\ub9ac\ub294 \ub610\ud55c \uc2dc\uc2a4\ud15c \uba54\uc2dc\uc9c0\uc640 \uac19\uc740 \ub354 \ub9ce\uc740 \uad6c\uc131\uc744 \uc218\uc6a9\ud558\ub3c4\ub85d \uadf8\ub798\ud504\ub97c \uc870\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4!\n"]}, {"cell_type": "code", "execution_count": 7, "id": "f0393a43-9fbe-4056-972f-3e91ea329041", "metadata": {}, "outputs": [], "source": ["from langchain_core.messages import SystemMessage\n", "\n", "\n", "# We can define a config schema to specify the configuration options for the graph\n", "# A config schema is useful for indicating which fields are available in the configurable dict inside the config\n", "class ConfigSchema(TypedDict):\n", "    model: Optional[str]\n", "    system_message: Optional[str]\n", "\n", "\n", "def _call_model(state: AgentState, config: RunnableConfig):\n", "    # Access the config through the configurable key\n", "    model_name = config[\"configurable\"].get(\"model\", \"anthropic\")\n", "    model = models[model_name]\n", "    messages = state[\"messages\"]\n", "    if \"system_message\" in config[\"configurable\"]:\n", "        messages = [\n", "            SystemMessage(content=config[\"configurable\"][\"system_message\"])\n", "        ] + messages\n", "    response = model.invoke(messages)\n", "    return {\"messages\": [response]}\n", "\n", "\n", "# Define a new graph - note that we pass in the configuration schema here, but it is not necessary\n", "workflow = StateGraph(AgentState, ConfigSchema)\n", "workflow.add_node(\"model\", _call_model)\n", "workflow.add_edge(START, \"model\")\n", "workflow.add_edge(\"model\", END)\n", "\n", "graph = workflow.compile()\n"]}, {"cell_type": "code", "execution_count": 8, "id": "718685f7-4cdd-4181-9fc8-e7762d584727", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'messages': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}),\n", "  AIMessage(content='Hello!', additional_kwargs={}, response_metadata={'id': 'msg_01VgCANVHr14PsHJSXyKkLVh', 'model': 'claude-2.1', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 10, 'output_tokens': 6}}, id='run-f8c5f18c-be58-4e44-9a4e-d43692d7eed1-0', usage_metadata={'input_tokens': 10, 'output_tokens': 6, 'total_tokens': 16})]}"]}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": ["graph.invoke({\"messages\": [HumanMessage(content=\"hi\")]})\n"]}, {"cell_type": "code", "execution_count": 9, "id": "e043a719-f197-46ef-9d45-84740a39aeb0", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'messages': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}),\n", "  AIMessage(content='Ciao!', additional_kwargs={}, response_metadata={'id': 'msg_011YuCYQk1Rzc8PEhVCpQGr6', 'model': 'claude-2.1', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 14, 'output_tokens': 7}}, id='run-a583341e-5868-4e8c-a536-881338f21252-0', usage_metadata={'input_tokens': 14, 'output_tokens': 7, 'total_tokens': 21})]}"]}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": ["config = {\"configurable\": {\"system_message\": \"respond in italian\"}}\n", "graph.invoke({\"messages\": [HumanMessage(content=\"hi\")]}, config=config)\n"]}], "metadata": {}}