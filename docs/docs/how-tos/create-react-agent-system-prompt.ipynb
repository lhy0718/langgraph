{"cells": [{"cell_type": "markdown", "id": "992c4695-ec4f-428d-bd05-fb3b5fbd70f4", "metadata": {}, "source": ["# \uc0ac\uc804 \uad6c\ucd95\ub41c ReAct \uc5d0\uc774\uc804\ud2b8\uc5d0 \uc0ac\uc6a9\uc790 \uc9c0\uc815 \uc2dc\uc2a4\ud15c \ud504\ub86c\ud504\ud2b8 \ucd94\uac00\ud558\ub294 \ubc29\ubc95\n", "\n", "<div class=\"admonition tip\">\n", "    <p class=\"admonition-title\">\uc804\uc81c \uc870\uac74</p>\n", "    <p>\n", "        \uc774 \uac00\uc774\ub4dc\ub294 \ub2e4\uc74c\uc5d0 \ub300\ud55c \uc774\ud574\ub97c \uac00\uc815\ud569\ub2c8\ub2e4:\n", "        <ul>\n", "            <li>            \n", "                <a href=\"https://python.langchain.com/docs/concepts/messages/#systemmessage\">\n", "                    SystemMessage\n", "                </a>\n", "            </li>\n", "            <li>\n", "                <a href=\"https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/\">\n", "                    \uc5d0\uc774\uc804\ud2b8 \uc544\ud0a4\ud14d\ucc98\n", "                </a>                   \n", "            </li>\n", "            <li>\n", "                <a href=\"https://python.langchain.com/docs/concepts/chat_models/\">\n", "                    \ucc44\ud305 \ubaa8\ub378\n", "                </a>\n", "            </li>\n", "            <li>\n", "                <a href=\"https://python.langchain.com/docs/concepts/tools/\">\n", "                    \ub3c4\uad6c\n", "                </a>\n", "            </li>\n", "        </ul>\n", "    </p>\n", "</div> \n", "\n", "\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 [\uc0ac\uc804 \uad6c\ucd95\ub41c ReAct \uc5d0\uc774\uc804\ud2b8](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent)\uc5d0 \uc0ac\uc6a9\uc790 \uc9c0\uc815 \uc2dc\uc2a4\ud15c \ud504\ub86c\ud504\ud2b8\ub97c \ucd94\uac00\ud558\ub294 \ubc29\ubc95\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc0ac\uc804 \uad6c\ucd95\ub41c ReAct \uc5d0\uc774\uc804\ud2b8\ub97c \uc2dc\uc791\ud558\ub294 \ubc29\ubc95\uc5d0 \ub300\ud574\uc11c\ub294 [\uc774 \ud29c\ud1a0\ub9ac\uc5bc](../create-react-agent)\uc744 \ucc38\uc870\ud558\uc138\uc694.\n", "\n", "\ubb38\uc790\uc5f4\uc744 `prompt` \ub9e4\uac1c\ubcc0\uc218\ub85c \uc804\ub2ec\ud558\uc5ec \uc0ac\uc6a9\uc790 \uc9c0\uc815 \uc2dc\uc2a4\ud15c \ud504\ub86c\ud504\ud2b8\ub97c \ucd94\uac00\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n"]}, {"cell_type": "markdown", "id": "7be3889f-3c17-4fa1-bd2b-84114a2c7247", "metadata": {}, "source": ["## \uc124\uc815\n", "\n", "\uba3c\uc800, \ud544\uc694\ud55c \ud328\ud0a4\uc9c0\ub97c \uc124\uce58\ud558\uace0 API \ud0a4\ub97c \uc124\uc815\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n"]}, {"cell_type": "code", "execution_count": 1, "id": "a213e11a-5c62-4ddb-a707-490d91add383", "metadata": {}, "outputs": [], "source": ["%%capture --no-stderr\n", "%pip install -U langgraph langchain-openai\n"]}, {"cell_type": "code", "execution_count": null, "id": "23a1885c-04ab-4750-aefa-105891fddf3e", "metadata": {}, "outputs": [], "source": ["import getpass\n", "import os\n", "\n", "\n", "def _set_env(var: str):\n", "    if not os.environ.get(var):\n", "        os.environ[var] = getpass.getpass(f\"{var}: \")\n", "\n", "\n", "_set_env(\"OPENAI_API_KEY\")\n"]}, {"cell_type": "markdown", "id": "715867c6", "metadata": {}, "source": ["<div class=\"admonition tip\">\n", "    <p class=\"admonition-title\">LangGraph \uac1c\ubc1c\uc744 \uc704\ud574 <a href=\"https://smith.langchain.com\">LangSmith</a> \uc124\uc815\ud558\uae30</p>\n", "    <p style=\"padding-top: 5px;\">\n", "        LangSmith\uc5d0 \uac00\uc785\ud558\uc5ec LangGraph \ud504\ub85c\uc81d\ud2b8\uc758 \ubb38\uc81c\ub97c \uc2e0\uc18d\ud558\uac8c \ud30c\uc545\ud558\uace0 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0ac \uc218 \uc788\uc2b5\ub2c8\ub2e4. LangSmith\ub97c \uc0ac\uc6a9\ud558\uba74 LangGraph\ub85c \uad6c\ucd95\ub41c LLM \uc571\uc744 \ub514\ubc84\uadf8\ud558\uace0, \ud14c\uc2a4\ud2b8\ud558\uace0, \ubaa8\ub2c8\ud130\ub9c1\ud558\uae30 \uc704\ud55c \ucd94\uc801 \ub370\uc774\ud130\ub97c \ud65c\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4 \u2014 \uc2dc\uc791\ud558\ub294 \ubc29\ubc95\uc5d0 \ub300\ud574 \ub354 \uc77d\uc5b4\ubcf4\ub824\uba74 <a href=\"https://docs.smith.langchain.com\">\uc5ec\uae30</a>\ub97c \ud074\ub9ad\ud558\uc138\uc694.\n", "    </p>\n", "</div>\n"]}, {"cell_type": "markdown", "id": "03c0f089-070c-4cd4-87e0-6c51f2477b82", "metadata": {}, "source": ["## \ucf54\ub4dc\n"]}, {"cell_type": "code", "execution_count": 1, "id": "7a154152-973e-4b5d-aa13-48c617744a4c", "metadata": {}, "outputs": [], "source": ["# First we initialize the model we want to use.\n", "from langchain_openai import ChatOpenAI\n", "\n", "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n", "\n", "\n", "# For this tutorial we will use custom tool that returns pre-defined values for weather in two cities (NYC & SF)\n", "\n", "from typing import Literal\n", "\n", "from langchain_core.tools import tool\n", "\n", "\n", "@tool\n", "def get_weather(city: Literal[\"nyc\", \"sf\"]):\n", "    \"\"\"Use this to get weather information.\"\"\"\n", "    if city == \"nyc\":\n", "        return \"It might be cloudy in nyc\"\n", "    elif city == \"sf\":\n", "        return \"It's always sunny in sf\"\n", "    else:\n", "        raise AssertionError(\"Unknown city\")\n", "\n", "\n", "tools = [get_weather]\n", "\n", "# We can add our system prompt here\n", "\n", "prompt = \"Respond in Italian\"\n", "\n", "# Define the graph\n", "\n", "from langgraph.prebuilt import create_react_agent\n", "\n", "graph = create_react_agent(model, tools=tools, prompt=prompt)\n"]}, {"cell_type": "markdown", "id": "00407425-506d-4ffd-9c86-987921d8c844", "metadata": {}, "source": ["## \uc0ac\uc6a9\ubc95\n"]}, {"cell_type": "code", "execution_count": 2, "id": "16636975-5f2d-4dc7-ab8e-d0bea0830a28", "metadata": {}, "outputs": [], "source": ["def print_stream(stream):\n", "    for s in stream:\n", "        message = s[\"messages\"][-1]\n", "        if isinstance(message, tuple):\n", "            print(message)\n", "        else:\n", "            message.pretty_print()\n"]}, {"cell_type": "code", "execution_count": 4, "id": "9ffff6c3-a4f5-47c9-b51d-97caaee85cd6", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["================================\u001b[1m Human Message \u001b[0m=================================\n", "\n", "What's the weather in NYC?\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "Tool Calls:\n", "  get_weather (call_b02uzBRrIm2uciJa8zDXCDxT)\n", " Call ID: call_b02uzBRrIm2uciJa8zDXCDxT\n", "  Args:\n", "    city: nyc\n", "=================================\u001b[1m Tool Message \u001b[0m=================================\n", "Name: get_weather\n", "\n", "It might be cloudy in nyc\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "\n", "A New York potrebbe essere nuvoloso.\n"]}], "source": ["inputs = {\"messages\": [(\"user\", \"What's the weather in NYC?\")]}\n", "\n", "print_stream(graph.stream(inputs, stream_mode=\"values\"))\n"]}], "metadata": {"translated_ko": true}}